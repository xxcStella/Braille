{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import sinabs\n",
    "import sinabs.activation\n",
    "import sinabs.layers as sl\n",
    "from sinabs.from_torch import from_model\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import KFold\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.data_path = os.listdir(self.root_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_name = self.data_path[idx]\n",
    "        data_item_path = os.path.join(self.root_dir, data_name)\n",
    "        with open(data_item_path, 'rb') as f:\n",
    "            data = np.load(f)\n",
    "\n",
    "        data = torch.from_numpy(data).float()\n",
    "        data = torch.transpose(data, 0, 1)\n",
    "\n",
    "        label = torch.tensor(eval(data_name[-5]), dtype=torch.long)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "root_dir_1 = 'F:\\Files\\PhD\\Braille\\Data/braille-27letters-sphere/depth/depth-1.5mm/train'\n",
    "root_dir_2 = 'F:\\Files\\PhD\\Braille\\Data/braille-27letters-sphere/depth/depth-1.5mm/test'\n",
    "\n",
    "train_data = MyData(root_dir_1)\n",
    "test_data  = MyData(root_dir_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Softwares\\Professional\\Anaconda3\\envs\\synsense-gpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 13.61%, running_loss: 151.10, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 17.42%, running_loss: 150.70, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 18.38%, running_loss: 150.73, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 22.58%, running_loss: 132.80, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 30.18%, running_loss: 117.59, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 36.93%, running_loss: 105.80, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 42.44%, running_loss: 94.92, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 49.74%, running_loss: 84.75, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 52.78%, running_loss: 78.93, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 55.91%, running_loss: 73.20, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 57.97%, running_loss: 67.89, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 60.74%, running_loss: 63.45, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 64.33%, running_loss: 58.21, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 64.97%, running_loss: 55.96, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 68.04%, running_loss: 50.69, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 69.60%, running_loss: 48.76, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 71.50%, running_loss: 45.66, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 72.62%, running_loss: 42.65, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 74.24%, running_loss: 39.94, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 75.64%, running_loss: 37.47, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 75.56%, running_loss: 36.59, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 76.43%, running_loss: 36.42, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 75.67%, running_loss: 36.56, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 76.32%, running_loss: 36.32, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 76.16%, running_loss: 36.08, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 76.71%, running_loss: 35.61, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 76.41%, running_loss: 35.56, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 76.79%, running_loss: 34.97, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 76.35%, running_loss: 34.87, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 77.20%, running_loss: 34.51, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 77.61%, running_loss: 34.08, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 77.20%, running_loss: 34.34, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 77.50%, running_loss: 34.38, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 77.56%, running_loss: 34.00, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 77.91%, running_loss: 33.57, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 77.86%, running_loss: 33.47, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 78.08%, running_loss: 33.07, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 78.13%, running_loss: 33.11, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 78.22%, running_loss: 32.79, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 78.49%, running_loss: 32.52, current_lr: 0.000001\n",
      "accuracy on validation set: 73.09%\n",
      "epoch: 0, accuracy: 11.99%, running_loss: 148.69, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 17.12%, running_loss: 144.00, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 26.78%, running_loss: 129.75, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 36.71%, running_loss: 109.43, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 43.37%, running_loss: 96.16, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 48.42%, running_loss: 86.33, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 52.10%, running_loss: 76.65, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 55.75%, running_loss: 70.25, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 58.79%, running_loss: 65.88, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 62.11%, running_loss: 59.96, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 63.90%, running_loss: 56.01, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 65.35%, running_loss: 54.49, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 67.16%, running_loss: 50.09, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 69.38%, running_loss: 46.60, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 70.78%, running_loss: 43.09, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 72.02%, running_loss: 42.84, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 74.65%, running_loss: 38.77, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 74.79%, running_loss: 36.53, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 76.60%, running_loss: 34.98, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 77.37%, running_loss: 32.94, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 77.50%, running_loss: 32.02, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 78.02%, running_loss: 31.93, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 78.05%, running_loss: 31.72, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 77.72%, running_loss: 31.70, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 78.60%, running_loss: 31.08, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 78.38%, running_loss: 30.95, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 78.30%, running_loss: 31.27, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 78.46%, running_loss: 31.13, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 78.35%, running_loss: 31.05, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 79.18%, running_loss: 30.59, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 79.23%, running_loss: 30.78, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 78.93%, running_loss: 30.42, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 79.62%, running_loss: 30.18, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 79.45%, running_loss: 29.86, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 79.64%, running_loss: 29.79, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 79.34%, running_loss: 29.31, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 79.67%, running_loss: 29.30, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 80.44%, running_loss: 28.80, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 79.97%, running_loss: 28.85, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 80.74%, running_loss: 28.72, current_lr: 0.000001\n",
      "accuracy on validation set: 78.77%\n",
      "epoch: 0, accuracy: 10.59%, running_loss: 152.62, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 16.43%, running_loss: 148.79, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 15.72%, running_loss: 157.59, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 21.89%, running_loss: 142.00, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 30.84%, running_loss: 125.12, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 38.38%, running_loss: 110.24, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 45.10%, running_loss: 97.75, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 49.33%, running_loss: 89.06, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 54.84%, running_loss: 78.64, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 57.42%, running_loss: 73.72, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 59.59%, running_loss: 69.01, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 62.74%, running_loss: 61.37, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 64.88%, running_loss: 56.20, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 67.30%, running_loss: 54.29, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 68.48%, running_loss: 50.82, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 70.59%, running_loss: 48.00, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 72.15%, running_loss: 45.28, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 73.50%, running_loss: 42.68, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 74.92%, running_loss: 40.79, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 76.24%, running_loss: 37.95, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 75.64%, running_loss: 37.18, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 75.94%, running_loss: 36.46, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 76.35%, running_loss: 36.56, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 76.90%, running_loss: 36.01, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 77.04%, running_loss: 36.12, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 76.30%, running_loss: 36.26, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 76.84%, running_loss: 35.67, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 76.74%, running_loss: 35.71, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 76.98%, running_loss: 35.49, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 76.84%, running_loss: 35.24, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 76.65%, running_loss: 35.27, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 76.90%, running_loss: 35.21, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 77.20%, running_loss: 34.79, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 77.31%, running_loss: 34.52, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 77.64%, running_loss: 34.00, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 77.53%, running_loss: 34.20, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 78.46%, running_loss: 33.07, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 78.00%, running_loss: 33.44, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 78.52%, running_loss: 33.10, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 78.66%, running_loss: 33.05, current_lr: 0.000001\n",
      "accuracy on validation set: 76.79%\n",
      "epoch: 0, accuracy: 16.93%, running_loss: 147.19, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 17.61%, running_loss: 144.49, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 23.95%, running_loss: 129.69, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 35.53%, running_loss: 107.75, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 43.37%, running_loss: 92.49, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 49.27%, running_loss: 81.70, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 54.60%, running_loss: 72.45, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 57.81%, running_loss: 68.16, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 58.98%, running_loss: 64.03, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 61.54%, running_loss: 60.27, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 64.03%, running_loss: 55.47, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 66.53%, running_loss: 52.88, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 67.60%, running_loss: 51.07, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 68.75%, running_loss: 49.06, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 69.49%, running_loss: 46.63, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 72.65%, running_loss: 44.10, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 72.95%, running_loss: 43.19, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 74.40%, running_loss: 39.99, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 75.36%, running_loss: 39.55, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 75.67%, running_loss: 36.94, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 76.13%, running_loss: 36.00, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 76.02%, running_loss: 35.68, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 75.45%, running_loss: 35.91, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 75.97%, running_loss: 36.35, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 76.02%, running_loss: 35.81, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 76.65%, running_loss: 35.19, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 76.49%, running_loss: 35.13, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 76.57%, running_loss: 34.94, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 76.98%, running_loss: 34.55, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 76.74%, running_loss: 34.29, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 76.93%, running_loss: 34.64, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 77.53%, running_loss: 33.79, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 77.56%, running_loss: 34.11, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 77.12%, running_loss: 33.85, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 77.23%, running_loss: 33.65, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 77.61%, running_loss: 33.54, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 77.53%, running_loss: 33.10, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 77.45%, running_loss: 33.22, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 77.72%, running_loss: 32.74, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 77.67%, running_loss: 32.69, current_lr: 0.000001\n",
      "accuracy on validation set: 77.28%\n",
      "epoch: 0, accuracy: 11.11%, running_loss: 148.77, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 17.37%, running_loss: 145.14, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 21.56%, running_loss: 141.20, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 26.34%, running_loss: 128.98, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 34.65%, running_loss: 116.40, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 41.04%, running_loss: 103.27, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 46.20%, running_loss: 93.13, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 49.38%, running_loss: 84.28, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 52.37%, running_loss: 78.50, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 57.15%, running_loss: 71.00, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 59.86%, running_loss: 64.53, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 62.80%, running_loss: 61.42, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 63.84%, running_loss: 56.97, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 66.89%, running_loss: 52.35, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 68.48%, running_loss: 50.42, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 69.41%, running_loss: 47.94, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 71.80%, running_loss: 42.90, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 72.81%, running_loss: 42.10, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 74.02%, running_loss: 40.00, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 75.34%, running_loss: 37.17, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 75.91%, running_loss: 36.26, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 75.47%, running_loss: 36.12, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 75.25%, running_loss: 35.93, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 75.97%, running_loss: 35.60, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 75.72%, running_loss: 35.12, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 76.16%, running_loss: 34.82, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 76.05%, running_loss: 34.89, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 75.97%, running_loss: 34.66, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 76.21%, running_loss: 34.20, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 76.49%, running_loss: 34.90, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 76.46%, running_loss: 34.76, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 76.32%, running_loss: 34.90, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 76.82%, running_loss: 34.45, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 76.84%, running_loss: 33.88, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 76.98%, running_loss: 33.79, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 77.01%, running_loss: 33.15, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 76.90%, running_loss: 33.32, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 77.15%, running_loss: 32.81, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 77.45%, running_loss: 32.80, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 77.78%, running_loss: 31.98, current_lr: 0.000001\n",
      "accuracy on validation set: 78.02%\n",
      "epoch: 0, accuracy: 17.09%, running_loss: 145.24, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 21.45%, running_loss: 140.00, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 24.28%, running_loss: 126.87, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 28.81%, running_loss: 119.48, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 32.92%, running_loss: 110.30, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 39.09%, running_loss: 100.54, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 44.17%, running_loss: 91.42, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 47.05%, running_loss: 86.30, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 50.23%, running_loss: 78.73, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 56.08%, running_loss: 73.02, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 57.70%, running_loss: 66.67, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 59.95%, running_loss: 62.39, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 63.40%, running_loss: 57.31, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 65.93%, running_loss: 53.68, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 68.23%, running_loss: 50.18, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 69.90%, running_loss: 46.89, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 71.19%, running_loss: 43.63, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 72.73%, running_loss: 42.62, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 74.35%, running_loss: 40.33, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 75.01%, running_loss: 37.16, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 75.20%, running_loss: 36.74, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 75.88%, running_loss: 36.90, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 75.94%, running_loss: 36.82, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 75.88%, running_loss: 36.97, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 76.05%, running_loss: 36.11, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 75.94%, running_loss: 36.79, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 76.19%, running_loss: 36.43, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 76.27%, running_loss: 36.24, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 76.38%, running_loss: 36.04, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 76.24%, running_loss: 35.57, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 76.52%, running_loss: 35.27, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 76.71%, running_loss: 34.97, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 76.57%, running_loss: 35.13, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 76.68%, running_loss: 35.29, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 77.15%, running_loss: 34.92, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 76.57%, running_loss: 34.72, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 76.87%, running_loss: 34.20, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 77.39%, running_loss: 34.33, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 77.45%, running_loss: 34.10, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 77.59%, running_loss: 33.66, current_lr: 0.000001\n",
      "accuracy on validation set: 76.05%\n",
      "epoch: 0, accuracy: 17.67%, running_loss: 145.76, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 21.95%, running_loss: 143.32, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 25.79%, running_loss: 130.13, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 33.33%, running_loss: 112.78, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 40.55%, running_loss: 100.61, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 44.66%, running_loss: 93.76, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 48.40%, running_loss: 84.83, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 53.61%, running_loss: 74.89, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 57.26%, running_loss: 68.00, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 60.14%, running_loss: 61.34, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 63.48%, running_loss: 56.98, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 66.06%, running_loss: 52.02, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 67.87%, running_loss: 50.09, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 69.88%, running_loss: 46.28, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 71.22%, running_loss: 44.72, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 73.17%, running_loss: 42.42, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 74.27%, running_loss: 39.85, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 75.03%, running_loss: 38.19, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 75.72%, running_loss: 36.33, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 77.70%, running_loss: 34.10, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 77.83%, running_loss: 33.19, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 77.53%, running_loss: 33.60, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 78.16%, running_loss: 33.12, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 77.56%, running_loss: 33.70, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 78.66%, running_loss: 33.68, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 78.49%, running_loss: 33.40, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 78.38%, running_loss: 32.92, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 78.41%, running_loss: 32.90, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 78.41%, running_loss: 33.14, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 78.13%, running_loss: 32.53, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 78.00%, running_loss: 32.50, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 78.16%, running_loss: 31.84, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 79.31%, running_loss: 31.91, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 79.09%, running_loss: 31.41, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 79.01%, running_loss: 31.16, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 78.93%, running_loss: 31.12, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 79.20%, running_loss: 31.14, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 79.15%, running_loss: 31.43, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 79.53%, running_loss: 30.77, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 79.29%, running_loss: 30.24, current_lr: 0.000001\n",
      "accuracy on validation set: 80.99%\n",
      "epoch: 0, accuracy: 18.90%, running_loss: 144.82, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 26.97%, running_loss: 130.40, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 34.71%, running_loss: 109.76, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 41.04%, running_loss: 95.98, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 47.00%, running_loss: 85.98, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 50.84%, running_loss: 79.96, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 54.46%, running_loss: 72.77, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 56.35%, running_loss: 69.26, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 58.46%, running_loss: 63.90, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 60.74%, running_loss: 59.27, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 63.65%, running_loss: 55.67, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 65.98%, running_loss: 50.49, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 66.36%, running_loss: 49.50, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 68.12%, running_loss: 48.11, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 70.18%, running_loss: 45.24, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 71.63%, running_loss: 40.77, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 74.27%, running_loss: 38.18, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 75.03%, running_loss: 37.43, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 77.53%, running_loss: 34.25, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 77.91%, running_loss: 32.45, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 78.19%, running_loss: 31.52, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 77.78%, running_loss: 31.64, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 78.02%, running_loss: 31.25, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 78.05%, running_loss: 31.52, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 77.64%, running_loss: 31.40, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 78.44%, running_loss: 31.12, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 78.52%, running_loss: 31.31, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 78.74%, running_loss: 30.97, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 78.38%, running_loss: 31.12, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 78.71%, running_loss: 30.85, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 78.57%, running_loss: 30.49, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 78.88%, running_loss: 30.70, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 78.71%, running_loss: 30.05, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 78.96%, running_loss: 30.13, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 78.98%, running_loss: 29.97, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 78.66%, running_loss: 29.54, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 78.96%, running_loss: 29.25, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 78.85%, running_loss: 29.57, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 79.70%, running_loss: 29.25, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 79.34%, running_loss: 29.15, current_lr: 0.000001\n",
      "accuracy on validation set: 80.49%\n",
      "epoch: 0, accuracy: 15.39%, running_loss: 147.09, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 14.79%, running_loss: 145.88, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 16.68%, running_loss: 140.37, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 24.99%, running_loss: 124.28, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 36.68%, running_loss: 108.71, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 43.18%, running_loss: 97.21, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 48.01%, running_loss: 87.72, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 51.33%, running_loss: 80.02, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 55.17%, running_loss: 71.07, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 59.26%, running_loss: 65.56, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 62.19%, running_loss: 61.95, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 64.53%, running_loss: 55.46, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 65.90%, running_loss: 52.96, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 68.81%, running_loss: 50.56, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 69.52%, running_loss: 47.33, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 71.91%, running_loss: 43.77, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 72.65%, running_loss: 42.29, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 74.62%, running_loss: 40.04, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 75.53%, running_loss: 37.74, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 77.09%, running_loss: 34.98, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 76.90%, running_loss: 34.43, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 77.48%, running_loss: 33.65, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 77.39%, running_loss: 33.71, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 77.23%, running_loss: 34.01, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 77.59%, running_loss: 33.83, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 77.26%, running_loss: 33.99, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 77.83%, running_loss: 33.86, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 77.53%, running_loss: 33.42, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 77.81%, running_loss: 33.77, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 77.61%, running_loss: 34.25, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 77.83%, running_loss: 33.73, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 77.50%, running_loss: 33.91, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 78.27%, running_loss: 33.72, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 78.33%, running_loss: 33.15, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 77.83%, running_loss: 33.33, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 78.30%, running_loss: 32.87, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 78.85%, running_loss: 32.61, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 78.60%, running_loss: 31.98, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 78.38%, running_loss: 31.58, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 79.45%, running_loss: 31.12, current_lr: 0.000001\n",
      "accuracy on validation set: 78.77%\n",
      "epoch: 0, accuracy: 16.65%, running_loss: 147.19, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 23.24%, running_loss: 136.88, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 28.20%, running_loss: 127.91, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 34.81%, running_loss: 118.73, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 38.96%, running_loss: 109.78, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 42.80%, running_loss: 98.80, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 47.93%, running_loss: 88.12, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 51.30%, running_loss: 80.53, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 55.28%, running_loss: 72.70, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 57.61%, running_loss: 66.10, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 61.98%, running_loss: 60.39, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 63.54%, running_loss: 56.27, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 65.95%, running_loss: 53.19, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 68.50%, running_loss: 48.46, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 69.11%, running_loss: 48.57, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 71.19%, running_loss: 46.05, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 72.54%, running_loss: 42.03, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 73.94%, running_loss: 40.64, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 75.23%, running_loss: 38.72, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 75.97%, running_loss: 36.37, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 75.72%, running_loss: 36.38, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 75.69%, running_loss: 36.18, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 76.02%, running_loss: 35.71, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 75.80%, running_loss: 36.12, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 76.43%, running_loss: 35.66, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 76.32%, running_loss: 35.18, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 77.37%, running_loss: 35.33, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 76.98%, running_loss: 34.74, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 77.61%, running_loss: 34.40, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 77.81%, running_loss: 34.04, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 77.97%, running_loss: 33.75, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 78.16%, running_loss: 34.15, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 77.72%, running_loss: 33.99, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 78.08%, running_loss: 33.47, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 77.59%, running_loss: 33.63, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 77.78%, running_loss: 33.68, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 78.35%, running_loss: 33.29, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 78.85%, running_loss: 32.99, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 78.41%, running_loss: 32.93, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 78.93%, running_loss: 32.52, current_lr: 0.000001\n",
      "accuracy on validation set: 78.27%\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "device = 'cuda:0'\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=False)\n",
    "batch_size = 81\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "fold_train_acc = []\n",
    "fold_val_acc = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data)):\n",
    "    # 模型初始化\n",
    "    linear_model = nn.Sequential(\n",
    "        nn.Linear(100, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 27)\n",
    "    )\n",
    "    linear_model = from_model(linear_model, batch_size=81, input_shape=(1, 720, 100), \n",
    "                              add_spiking_output=True).to(device)\n",
    "    optimizer = torch.optim.Adam(linear_model.parameters(), lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    # 分割数据集\n",
    "    train_sub = Subset(train_data, train_ids)\n",
    "    val_sub = Subset(train_data, val_ids)\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_sub, batch_size, shuffle=True)\n",
    "    val_loader  = DataLoader(val_sub, batch_size)\n",
    "\n",
    "    # 训练模型\n",
    "    linear_model.train()\n",
    "    epochs = 40\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0.\n",
    "        acc = 0\n",
    "        scheduler.step()\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            linear_model.reset_states()\n",
    "\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(input)\n",
    "            sum_output = output.sum(1)\n",
    "            loss = loss_fn(sum_output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                if sum_output[j].argmax() == target[j]:\n",
    "                    acc += 1\n",
    "\n",
    "        print(\"epoch: %d, accuracy: %.2f%%, running_loss: %.2f, current_lr: %.6f\" \n",
    "              % (e, acc/len(train_sub)*100, running_loss, scheduler.get_last_lr()[0]) )\n",
    "    fold_train_acc.append(np.around(acc/len(train_sub)*100, 2))\n",
    "\n",
    "    # 验证模型\n",
    "    acc_num = 0\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            linear_model.reset_states()\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(data)\n",
    "            sum_output = output.sum(1)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            if sum_output[j].argmax() == target[j]:\n",
    "                acc_num += 1\n",
    "    print(\"accuracy on validation set: %.2f%%\" % (acc_num/len(val_sub)*100))\n",
    "    fold_val_acc.append(np.around(acc_num/len(val_sub)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78.49, 80.74, 78.66, 77.67, 77.78, 77.59, 79.29, 79.34, 79.45, 78.93]\n",
      "[73.09, 78.77, 76.79, 77.28, 78.02, 76.05, 80.99, 80.49, 78.77, 78.27]\n",
      "78.79400000000001\n",
      "77.852\n"
     ]
    }
   ],
   "source": [
    "print(fold_train_acc)\n",
    "print(fold_val_acc)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_train_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_val_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/neuron-100.pth'\n",
    "torch.save(linear_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testing set: 74.98%\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(model_path)\n",
    "test_loader  = DataLoader(test_data, batch_size)\n",
    "\n",
    "acc_num = 0\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.reset_states()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        sum_output = output.sum(1)\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        if sum_output[j].argmax() == target[j]:\n",
    "            acc_num += 1\n",
    "print(\"accuracy on testing set: %.2f%%\" % (acc_num/len(test_data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synsense-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
