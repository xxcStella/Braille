{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import sinabs\n",
    "import sinabs.activation\n",
    "import sinabs.layers as sl\n",
    "from sinabs.from_torch import from_model\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import KFold\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.data_path = os.listdir(self.root_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_name = self.data_path[idx]\n",
    "        data_item_path = os.path.join(self.root_dir, data_name)\n",
    "        with open(data_item_path, 'rb') as f:\n",
    "            data = np.load(f)\n",
    "\n",
    "        data = torch.from_numpy(data).float()\n",
    "        data = torch.transpose(data, 0, 1)\n",
    "\n",
    "        label = torch.tensor(eval(data_name[-5]), dtype=torch.long)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "root_dir_1 = 'F:\\Files\\PhD\\Braille\\Data/braille-27letters-sphere/depth/depth-1.5mm/train'\n",
    "root_dir_2 = 'F:\\Files\\PhD\\Braille\\Data/braille-27letters-sphere/depth/depth-1.5mm/test'\n",
    "\n",
    "train_data = MyData(root_dir_1)\n",
    "test_data  = MyData(root_dir_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Softwares\\Professional\\Anaconda3\\envs\\synsense-gpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 21.10%, running_loss: 145.69, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 39.01%, running_loss: 107.12, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 52.32%, running_loss: 75.15, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 60.52%, running_loss: 58.89, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 67.63%, running_loss: 48.66, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 72.15%, running_loss: 39.90, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 75.69%, running_loss: 35.05, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 78.33%, running_loss: 29.99, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 80.25%, running_loss: 27.44, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 82.91%, running_loss: 23.15, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 84.12%, running_loss: 20.50, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 86.28%, running_loss: 18.42, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 87.24%, running_loss: 17.90, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 87.85%, running_loss: 16.51, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 88.86%, running_loss: 14.74, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 89.03%, running_loss: 14.32, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 89.88%, running_loss: 13.07, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 91.28%, running_loss: 10.97, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 91.58%, running_loss: 11.51, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 93.11%, running_loss: 8.92, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 93.22%, running_loss: 8.45, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 93.55%, running_loss: 8.64, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 93.69%, running_loss: 8.54, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 93.64%, running_loss: 8.34, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 93.77%, running_loss: 8.12, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 93.61%, running_loss: 8.14, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 93.69%, running_loss: 8.17, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 93.47%, running_loss: 8.14, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 93.72%, running_loss: 8.34, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 93.80%, running_loss: 8.08, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 93.72%, running_loss: 8.00, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 93.83%, running_loss: 8.01, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 94.10%, running_loss: 7.58, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 94.07%, running_loss: 7.73, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 94.02%, running_loss: 7.70, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 94.02%, running_loss: 7.44, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 94.02%, running_loss: 7.81, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 94.38%, running_loss: 7.17, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 93.94%, running_loss: 7.55, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 94.43%, running_loss: 7.06, current_lr: 0.000001\n",
      "accuracy on validation set: 93.83%\n",
      "epoch: 0, accuracy: 23.90%, running_loss: 138.51, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 42.69%, running_loss: 94.30, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 56.13%, running_loss: 68.10, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 62.66%, running_loss: 54.60, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 68.70%, running_loss: 43.55, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 72.65%, running_loss: 37.56, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 76.71%, running_loss: 32.40, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 78.11%, running_loss: 31.58, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 81.18%, running_loss: 26.61, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 84.42%, running_loss: 22.31, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 86.12%, running_loss: 19.66, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 87.24%, running_loss: 17.99, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 88.31%, running_loss: 15.42, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 89.30%, running_loss: 14.15, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 89.99%, running_loss: 13.70, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 91.50%, running_loss: 10.87, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 90.92%, running_loss: 11.88, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 91.99%, running_loss: 10.74, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 91.91%, running_loss: 10.16, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 92.84%, running_loss: 8.44, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 93.99%, running_loss: 7.62, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 93.74%, running_loss: 7.47, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 93.64%, running_loss: 7.68, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 94.10%, running_loss: 7.43, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 93.88%, running_loss: 7.16, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 93.96%, running_loss: 7.26, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 94.35%, running_loss: 6.94, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 93.72%, running_loss: 7.15, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 93.96%, running_loss: 7.21, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 93.85%, running_loss: 7.41, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 94.07%, running_loss: 7.10, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 94.46%, running_loss: 6.81, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 94.29%, running_loss: 6.69, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 94.21%, running_loss: 6.57, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 94.27%, running_loss: 6.81, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 94.24%, running_loss: 6.60, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 94.71%, running_loss: 6.49, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 94.84%, running_loss: 6.24, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 94.57%, running_loss: 6.22, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 95.03%, running_loss: 5.92, current_lr: 0.000001\n",
      "accuracy on validation set: 92.10%\n",
      "epoch: 0, accuracy: 21.43%, running_loss: 143.88, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 38.66%, running_loss: 109.43, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 50.56%, running_loss: 80.88, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 59.42%, running_loss: 62.04, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 66.17%, running_loss: 50.73, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 70.53%, running_loss: 42.88, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 74.27%, running_loss: 37.21, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 77.15%, running_loss: 32.16, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 80.00%, running_loss: 27.80, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 82.55%, running_loss: 23.74, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 84.03%, running_loss: 22.44, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 86.12%, running_loss: 19.25, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 87.46%, running_loss: 17.26, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 88.61%, running_loss: 15.25, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 89.22%, running_loss: 14.17, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 91.06%, running_loss: 12.10, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 91.03%, running_loss: 11.41, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 92.02%, running_loss: 11.29, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 92.43%, running_loss: 10.55, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 93.53%, running_loss: 8.60, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 94.16%, running_loss: 8.16, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 94.05%, running_loss: 7.90, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 94.32%, running_loss: 7.81, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 93.96%, running_loss: 7.97, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 94.43%, running_loss: 7.73, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 94.60%, running_loss: 7.84, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 94.38%, running_loss: 7.57, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 94.40%, running_loss: 7.71, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 94.38%, running_loss: 7.86, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 94.73%, running_loss: 7.50, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 94.32%, running_loss: 7.46, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 94.46%, running_loss: 7.40, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 94.68%, running_loss: 7.19, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 94.84%, running_loss: 6.90, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 94.76%, running_loss: 7.10, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 94.76%, running_loss: 6.95, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 94.71%, running_loss: 6.93, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 94.62%, running_loss: 6.89, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 94.79%, running_loss: 6.68, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 94.84%, running_loss: 6.55, current_lr: 0.000001\n",
      "accuracy on validation set: 93.58%\n",
      "epoch: 0, accuracy: 20.66%, running_loss: 141.28, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 37.67%, running_loss: 102.06, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 52.13%, running_loss: 75.28, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 61.67%, running_loss: 58.47, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 66.56%, running_loss: 51.10, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 72.10%, running_loss: 41.84, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 77.01%, running_loss: 32.78, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 79.75%, running_loss: 28.99, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 82.11%, running_loss: 25.73, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 84.36%, running_loss: 22.15, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 86.09%, running_loss: 19.07, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 86.61%, running_loss: 18.16, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 88.83%, running_loss: 14.93, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 88.42%, running_loss: 15.51, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 89.05%, running_loss: 15.36, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 90.43%, running_loss: 12.71, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 90.53%, running_loss: 12.27, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 90.53%, running_loss: 13.02, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 92.46%, running_loss: 10.17, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 93.85%, running_loss: 8.15, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 94.05%, running_loss: 7.79, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 94.02%, running_loss: 7.82, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 94.02%, running_loss: 7.78, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 93.83%, running_loss: 7.68, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 94.13%, running_loss: 7.55, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 94.29%, running_loss: 7.66, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 94.43%, running_loss: 7.51, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 94.57%, running_loss: 7.28, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 94.32%, running_loss: 7.39, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 94.57%, running_loss: 7.19, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 94.60%, running_loss: 7.08, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 94.81%, running_loss: 7.09, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 94.43%, running_loss: 7.08, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 94.62%, running_loss: 6.95, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 94.71%, running_loss: 6.62, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 94.71%, running_loss: 6.63, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 94.71%, running_loss: 6.49, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 94.71%, running_loss: 6.34, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 94.73%, running_loss: 6.39, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 95.09%, running_loss: 6.12, current_lr: 0.000001\n",
      "accuracy on validation set: 90.37%\n",
      "epoch: 0, accuracy: 19.45%, running_loss: 147.58, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 36.74%, running_loss: 114.61, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 51.08%, running_loss: 82.37, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 59.59%, running_loss: 62.04, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 65.24%, running_loss: 52.58, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 71.11%, running_loss: 42.78, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 75.12%, running_loss: 37.56, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 78.02%, running_loss: 31.65, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 80.93%, running_loss: 27.48, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 83.02%, running_loss: 24.09, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 83.54%, running_loss: 22.36, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 85.62%, running_loss: 19.55, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 87.19%, running_loss: 18.40, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 87.54%, running_loss: 17.42, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 88.72%, running_loss: 15.78, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 90.62%, running_loss: 13.34, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 90.18%, running_loss: 12.88, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 90.73%, running_loss: 12.62, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 91.60%, running_loss: 10.60, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 93.44%, running_loss: 8.55, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 93.96%, running_loss: 8.26, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 93.74%, running_loss: 8.40, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 93.69%, running_loss: 8.22, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 93.61%, running_loss: 8.40, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 93.91%, running_loss: 8.25, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 94.02%, running_loss: 8.08, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 94.21%, running_loss: 7.95, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 94.13%, running_loss: 7.98, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 94.10%, running_loss: 8.08, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 93.74%, running_loss: 8.13, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 93.94%, running_loss: 8.02, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 94.29%, running_loss: 7.60, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 94.27%, running_loss: 7.43, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 94.16%, running_loss: 7.67, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 94.24%, running_loss: 7.35, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 94.51%, running_loss: 7.40, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 94.71%, running_loss: 7.27, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 94.10%, running_loss: 7.46, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 94.35%, running_loss: 7.35, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 94.35%, running_loss: 7.22, current_lr: 0.000001\n",
      "accuracy on validation set: 89.88%\n",
      "epoch: 0, accuracy: 20.96%, running_loss: 143.64, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 40.41%, running_loss: 102.16, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 55.31%, running_loss: 71.23, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 62.19%, running_loss: 58.57, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 69.27%, running_loss: 45.27, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 72.57%, running_loss: 39.21, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 76.38%, running_loss: 33.11, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 78.63%, running_loss: 30.27, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 81.73%, running_loss: 25.03, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 83.35%, running_loss: 23.04, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 85.65%, running_loss: 19.90, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 85.57%, running_loss: 20.31, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 88.64%, running_loss: 15.31, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 89.11%, running_loss: 13.95, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 90.04%, running_loss: 12.70, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 90.40%, running_loss: 13.08, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 91.63%, running_loss: 10.59, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 91.82%, running_loss: 10.89, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 93.22%, running_loss: 8.94, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 94.21%, running_loss: 7.57, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 94.27%, running_loss: 7.17, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 94.54%, running_loss: 7.09, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 94.57%, running_loss: 7.27, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 94.49%, running_loss: 7.21, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 94.35%, running_loss: 7.26, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 94.54%, running_loss: 7.08, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 94.40%, running_loss: 7.20, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 94.40%, running_loss: 6.96, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 94.60%, running_loss: 7.13, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 94.65%, running_loss: 6.96, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 94.51%, running_loss: 6.78, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 94.46%, running_loss: 6.98, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 94.38%, running_loss: 6.93, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 94.90%, running_loss: 6.70, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 94.73%, running_loss: 6.52, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 95.50%, running_loss: 6.26, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 95.03%, running_loss: 6.37, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 95.39%, running_loss: 5.93, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 95.45%, running_loss: 6.02, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 95.56%, running_loss: 5.77, current_lr: 0.000001\n",
      "accuracy on validation set: 94.07%\n",
      "epoch: 0, accuracy: 21.92%, running_loss: 142.00, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 40.82%, running_loss: 102.37, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 53.06%, running_loss: 75.99, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 60.63%, running_loss: 59.64, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 67.54%, running_loss: 48.26, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 73.14%, running_loss: 40.30, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 76.49%, running_loss: 33.25, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 78.57%, running_loss: 29.69, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 82.03%, running_loss: 25.30, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 84.12%, running_loss: 22.80, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 85.57%, running_loss: 19.51, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 87.16%, running_loss: 17.05, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 87.74%, running_loss: 16.36, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 88.45%, running_loss: 15.71, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 90.07%, running_loss: 13.59, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 90.15%, running_loss: 13.43, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 91.80%, running_loss: 10.61, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 92.46%, running_loss: 10.52, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 92.24%, running_loss: 10.81, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 93.39%, running_loss: 8.15, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 94.13%, running_loss: 7.71, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 93.96%, running_loss: 7.64, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 94.10%, running_loss: 7.68, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 93.94%, running_loss: 7.59, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 94.13%, running_loss: 7.72, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 93.83%, running_loss: 7.65, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 93.80%, running_loss: 7.75, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 94.16%, running_loss: 7.31, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 94.24%, running_loss: 7.23, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 94.95%, running_loss: 7.11, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 94.68%, running_loss: 7.21, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 94.95%, running_loss: 6.92, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 94.71%, running_loss: 6.93, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 95.09%, running_loss: 6.87, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 94.90%, running_loss: 7.16, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 94.68%, running_loss: 6.94, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 94.95%, running_loss: 6.64, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 95.03%, running_loss: 6.56, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 95.14%, running_loss: 6.49, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 95.06%, running_loss: 6.29, current_lr: 0.000001\n",
      "accuracy on validation set: 96.05%\n",
      "epoch: 0, accuracy: 21.34%, running_loss: 140.98, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 41.89%, running_loss: 106.28, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 52.46%, running_loss: 78.67, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 61.48%, running_loss: 61.75, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 67.33%, running_loss: 50.31, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 70.12%, running_loss: 45.02, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 74.92%, running_loss: 35.98, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 76.76%, running_loss: 32.26, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 79.86%, running_loss: 28.77, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 81.67%, running_loss: 25.63, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 83.70%, running_loss: 23.09, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 86.39%, running_loss: 18.94, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 86.78%, running_loss: 18.70, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 87.49%, running_loss: 16.96, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 89.03%, running_loss: 15.29, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 89.99%, running_loss: 13.20, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 90.75%, running_loss: 12.62, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 90.86%, running_loss: 12.60, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 92.43%, running_loss: 10.55, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 93.39%, running_loss: 9.08, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 93.33%, running_loss: 8.69, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 93.53%, running_loss: 8.39, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 93.66%, running_loss: 8.47, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 93.77%, running_loss: 8.16, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 94.10%, running_loss: 8.21, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 93.99%, running_loss: 8.30, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 93.85%, running_loss: 8.20, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 93.96%, running_loss: 8.45, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 93.99%, running_loss: 8.08, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 93.94%, running_loss: 8.10, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 93.74%, running_loss: 8.14, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 93.80%, running_loss: 8.02, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 93.83%, running_loss: 7.93, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 93.94%, running_loss: 8.20, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 94.10%, running_loss: 7.80, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 94.49%, running_loss: 7.50, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 94.24%, running_loss: 7.53, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 94.43%, running_loss: 7.56, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 94.40%, running_loss: 7.47, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 94.32%, running_loss: 7.29, current_lr: 0.000001\n",
      "accuracy on validation set: 93.58%\n",
      "epoch: 0, accuracy: 23.40%, running_loss: 137.98, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 42.55%, running_loss: 101.54, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 53.03%, running_loss: 78.80, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 61.51%, running_loss: 58.75, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 67.33%, running_loss: 51.95, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 71.52%, running_loss: 42.44, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 76.16%, running_loss: 35.06, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 78.22%, running_loss: 31.32, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 81.73%, running_loss: 27.76, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 83.35%, running_loss: 24.43, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 84.94%, running_loss: 22.13, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 86.01%, running_loss: 20.00, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 87.57%, running_loss: 18.68, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 87.24%, running_loss: 17.84, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 88.97%, running_loss: 16.43, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 89.66%, running_loss: 15.62, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 89.27%, running_loss: 14.98, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 90.62%, running_loss: 12.88, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 92.21%, running_loss: 10.51, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 93.31%, running_loss: 8.95, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 93.20%, running_loss: 8.73, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 93.17%, running_loss: 8.78, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 93.39%, running_loss: 8.53, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 93.00%, running_loss: 8.56, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 93.36%, running_loss: 8.56, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 93.33%, running_loss: 8.40, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 93.31%, running_loss: 8.49, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 93.36%, running_loss: 8.40, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 93.66%, running_loss: 8.38, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 93.33%, running_loss: 8.54, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 93.28%, running_loss: 8.40, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 93.83%, running_loss: 8.04, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 93.44%, running_loss: 8.12, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 93.99%, running_loss: 7.96, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 93.94%, running_loss: 7.96, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 94.05%, running_loss: 7.60, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 93.99%, running_loss: 7.69, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 93.96%, running_loss: 7.89, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 94.16%, running_loss: 7.72, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 93.85%, running_loss: 7.91, current_lr: 0.000001\n",
      "accuracy on validation set: 93.58%\n",
      "epoch: 0, accuracy: 19.73%, running_loss: 143.37, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 40.82%, running_loss: 98.77, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 54.71%, running_loss: 70.58, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 62.41%, running_loss: 57.53, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 69.63%, running_loss: 45.10, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 73.22%, running_loss: 39.72, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 75.86%, running_loss: 34.86, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 79.97%, running_loss: 30.61, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 81.18%, running_loss: 26.37, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 82.96%, running_loss: 24.26, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 84.03%, running_loss: 21.96, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 86.50%, running_loss: 18.69, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 87.08%, running_loss: 18.06, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 88.92%, running_loss: 15.63, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 89.19%, running_loss: 14.61, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 89.88%, running_loss: 13.58, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 90.67%, running_loss: 12.22, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 90.95%, running_loss: 12.45, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 92.67%, running_loss: 9.99, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 93.61%, running_loss: 8.34, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 93.61%, running_loss: 8.34, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 93.99%, running_loss: 8.09, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 93.74%, running_loss: 8.14, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 94.18%, running_loss: 7.79, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 94.13%, running_loss: 7.81, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 93.80%, running_loss: 7.89, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 93.96%, running_loss: 7.85, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 94.32%, running_loss: 7.78, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 93.96%, running_loss: 7.81, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 94.16%, running_loss: 7.45, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 94.29%, running_loss: 7.56, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 94.16%, running_loss: 7.52, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 93.96%, running_loss: 7.61, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 94.35%, running_loss: 7.26, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 94.29%, running_loss: 7.35, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 94.35%, running_loss: 7.39, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 94.57%, running_loss: 7.27, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 94.62%, running_loss: 6.99, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 94.90%, running_loss: 6.79, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 95.09%, running_loss: 6.65, current_lr: 0.000001\n",
      "accuracy on validation set: 92.35%\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "device = 'cuda:0'\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=False)\n",
    "batch_size = 81\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "fold_train_acc = []\n",
    "fold_val_acc = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data)):\n",
    "    # 模型初始化\n",
    "    linear_model = nn.Sequential(\n",
    "        nn.Linear(100, 800),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(800, 27)\n",
    "    )\n",
    "    linear_model = from_model(linear_model, batch_size=81, input_shape=(1, 720, 100), \n",
    "                              add_spiking_output=True).to(device)\n",
    "    optimizer = torch.optim.Adam(linear_model.parameters(), lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    # 分割数据集\n",
    "    train_sub = Subset(train_data, train_ids)\n",
    "    val_sub = Subset(train_data, val_ids)\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_sub, batch_size, shuffle=True)\n",
    "    val_loader  = DataLoader(val_sub, batch_size)\n",
    "\n",
    "    # 训练模型\n",
    "    linear_model.train()\n",
    "    epochs = 40\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0.\n",
    "        acc = 0\n",
    "        scheduler.step()\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            linear_model.reset_states()\n",
    "\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(input)\n",
    "            sum_output = output.sum(1)\n",
    "            loss = loss_fn(sum_output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                if sum_output[j].argmax() == target[j]:\n",
    "                    acc += 1\n",
    "\n",
    "        print(\"epoch: %d, accuracy: %.2f%%, running_loss: %.2f, current_lr: %.6f\" \n",
    "              % (e, acc/len(train_sub)*100, running_loss, scheduler.get_last_lr()[0]) )\n",
    "    fold_train_acc.append(np.around(acc/len(train_sub)*100, 2))\n",
    "\n",
    "    # 验证模型\n",
    "    acc_num = 0\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            linear_model.reset_states()\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(data)\n",
    "            sum_output = output.sum(1)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            if sum_output[j].argmax() == target[j]:\n",
    "                acc_num += 1\n",
    "    print(\"accuracy on validation set: %.2f%%\" % (acc_num/len(val_sub)*100))\n",
    "    fold_val_acc.append(np.around(acc_num/len(val_sub)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94.43, 95.03, 94.84, 95.09, 94.35, 95.56, 95.06, 94.32, 93.85, 95.09]\n",
      "[93.83, 92.1, 93.58, 90.37, 89.88, 94.07, 96.05, 93.58, 93.58, 92.35]\n",
      "94.76199999999999\n",
      "92.939\n"
     ]
    }
   ],
   "source": [
    "print(fold_train_acc)\n",
    "print(fold_val_acc)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_train_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_val_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/neuron-800.pth'\n",
    "torch.save(linear_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testing set: 89.43%\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(model_path)\n",
    "test_loader  = DataLoader(test_data, batch_size)\n",
    "\n",
    "acc_num = 0\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.reset_states()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        sum_output = output.sum(1)\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        if sum_output[j].argmax() == target[j]:\n",
    "            acc_num += 1\n",
    "print(\"accuracy on testing set: %.2f%%\" % (acc_num/len(test_data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synsense-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
