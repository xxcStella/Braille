{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import sinabs\n",
    "import sinabs.activation\n",
    "import sinabs.layers as sl\n",
    "from sinabs.from_torch import from_model\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import KFold\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.data_path = os.listdir(self.root_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_name = self.data_path[idx]\n",
    "        data_item_path = os.path.join(self.root_dir, data_name)\n",
    "        with open(data_item_path, 'rb') as f:\n",
    "            data = np.load(f)\n",
    "\n",
    "        data = torch.from_numpy(data).float()\n",
    "        data = torch.transpose(data, 0, 1)\n",
    "\n",
    "        if data_name[-6] == '_':\n",
    "            label = torch.tensor(eval(data_name[-5]), dtype=torch.long)\n",
    "        else:\n",
    "            label = torch.tensor(eval(data_name[-6:-4]), dtype=torch.long)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "root_dir_1 = 'F:\\Files\\PhD/Braille\\Data/braille-27letters-sphere/effect-speed/speed-v200-depth2.5/train'\n",
    "root_dir_2 = 'F:\\Files\\PhD/Braille\\Data/braille-27letters-sphere/effect-speed/speed-v200-depth2.5/test'\n",
    "\n",
    "train_data = MyData(root_dir_1)\n",
    "test_data  = MyData(root_dir_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([700, 100])\n",
      "2160 1080\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][0].shape)\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Softwares\\Professional\\Anaconda3\\envs\\synsense-gpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 5.45%, running_loss: 79.03, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 6.79%, running_loss: 77.93, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 11.37%, running_loss: 75.00, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 18.31%, running_loss: 69.09, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 34.05%, running_loss: 53.40, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 49.02%, running_loss: 38.21, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 59.77%, running_loss: 29.88, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 68.21%, running_loss: 22.51, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 72.48%, running_loss: 19.52, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 78.81%, running_loss: 15.03, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 80.35%, running_loss: 13.05, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 82.15%, running_loss: 12.71, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 85.85%, running_loss: 9.60, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 87.65%, running_loss: 8.29, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 90.48%, running_loss: 6.72, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 91.05%, running_loss: 6.13, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 92.28%, running_loss: 5.42, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 93.11%, running_loss: 4.73, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 93.72%, running_loss: 4.48, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 94.44%, running_loss: 4.07, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 95.32%, running_loss: 3.17, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 95.88%, running_loss: 2.99, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 95.68%, running_loss: 3.21, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 95.27%, running_loss: 3.09, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 96.50%, running_loss: 2.94, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 96.09%, running_loss: 2.81, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 96.40%, running_loss: 2.40, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 95.47%, running_loss: 3.08, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 96.30%, running_loss: 2.73, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 95.83%, running_loss: 2.74, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 96.19%, running_loss: 2.78, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 95.99%, running_loss: 2.86, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 96.24%, running_loss: 2.48, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 96.24%, running_loss: 2.53, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 96.40%, running_loss: 2.41, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 96.91%, running_loss: 2.27, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 96.60%, running_loss: 2.45, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 96.55%, running_loss: 2.47, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 96.81%, running_loss: 2.38, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 96.24%, running_loss: 2.31, current_lr: 0.000001\n",
      "accuracy on validation set: 68.52%\n",
      "epoch: 0, accuracy: 3.65%, running_loss: 79.18, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 5.25%, running_loss: 78.81, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 8.44%, running_loss: 77.64, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 19.91%, running_loss: 67.82, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 34.26%, running_loss: 53.24, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 51.95%, running_loss: 36.29, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 61.21%, running_loss: 29.28, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 70.27%, running_loss: 21.34, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 75.41%, running_loss: 17.18, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 76.80%, running_loss: 15.22, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 83.13%, running_loss: 11.07, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 85.03%, running_loss: 10.70, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 87.35%, running_loss: 8.11, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 88.94%, running_loss: 7.69, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 90.69%, running_loss: 6.71, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 91.15%, running_loss: 6.05, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 93.42%, running_loss: 4.58, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 92.80%, running_loss: 4.67, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 94.19%, running_loss: 4.20, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 94.39%, running_loss: 3.74, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 96.81%, running_loss: 2.54, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 96.09%, running_loss: 2.54, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 95.73%, running_loss: 3.00, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 96.35%, running_loss: 2.59, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 95.78%, running_loss: 2.69, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 96.45%, running_loss: 2.79, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 96.81%, running_loss: 2.41, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 96.55%, running_loss: 2.54, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 96.14%, running_loss: 2.65, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 96.24%, running_loss: 2.44, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 96.86%, running_loss: 2.23, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 97.17%, running_loss: 2.19, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 96.09%, running_loss: 2.50, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 96.81%, running_loss: 2.29, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 96.71%, running_loss: 2.20, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 96.71%, running_loss: 2.27, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 97.12%, running_loss: 1.91, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 96.97%, running_loss: 2.17, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 97.63%, running_loss: 1.79, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 97.07%, running_loss: 1.93, current_lr: 0.000001\n",
      "accuracy on validation set: 71.30%\n",
      "epoch: 0, accuracy: 4.58%, running_loss: 79.12, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 6.89%, running_loss: 78.21, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 8.69%, running_loss: 76.83, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 12.91%, running_loss: 73.40, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 25.05%, running_loss: 63.87, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 40.02%, running_loss: 48.47, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 54.48%, running_loss: 35.81, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 63.37%, running_loss: 26.55, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 72.02%, running_loss: 19.73, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 77.52%, running_loss: 17.02, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 80.71%, running_loss: 14.51, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 83.18%, running_loss: 12.57, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 86.27%, running_loss: 9.33, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 88.84%, running_loss: 7.94, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 88.58%, running_loss: 7.50, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 90.79%, running_loss: 6.57, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 89.66%, running_loss: 6.86, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 92.49%, running_loss: 5.49, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 92.59%, running_loss: 4.74, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 94.80%, running_loss: 3.55, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 94.96%, running_loss: 3.61, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 95.06%, running_loss: 3.39, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 95.58%, running_loss: 3.12, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 95.01%, running_loss: 3.54, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 95.47%, running_loss: 3.09, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 94.80%, running_loss: 3.45, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 95.42%, running_loss: 2.69, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 95.78%, running_loss: 3.10, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 96.45%, running_loss: 2.53, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 95.68%, running_loss: 2.89, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 95.73%, running_loss: 2.71, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 96.35%, running_loss: 2.47, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 96.55%, running_loss: 2.47, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 96.40%, running_loss: 2.41, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 97.43%, running_loss: 2.07, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 96.45%, running_loss: 2.29, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 95.99%, running_loss: 2.71, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 96.04%, running_loss: 2.51, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 95.73%, running_loss: 2.74, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 96.09%, running_loss: 2.62, current_lr: 0.000001\n",
      "accuracy on validation set: 72.22%\n",
      "epoch: 0, accuracy: 3.96%, running_loss: 79.09, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 7.30%, running_loss: 77.61, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 9.72%, running_loss: 75.62, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 15.33%, running_loss: 71.67, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 29.89%, running_loss: 58.23, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 42.80%, running_loss: 44.34, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 55.92%, running_loss: 32.37, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 63.58%, running_loss: 25.38, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 73.05%, running_loss: 18.43, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 76.39%, running_loss: 15.70, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 81.02%, running_loss: 13.16, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 84.77%, running_loss: 10.56, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 85.91%, running_loss: 9.55, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 89.76%, running_loss: 6.59, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 91.00%, running_loss: 5.92, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 91.00%, running_loss: 5.93, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 92.28%, running_loss: 5.28, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 93.42%, running_loss: 4.44, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 93.52%, running_loss: 4.28, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 94.34%, running_loss: 3.32, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 95.58%, running_loss: 2.84, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 96.50%, running_loss: 2.54, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 96.40%, running_loss: 2.68, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 96.86%, running_loss: 2.41, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 95.47%, running_loss: 3.03, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 96.24%, running_loss: 2.57, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 96.60%, running_loss: 2.29, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 96.97%, running_loss: 2.34, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 96.40%, running_loss: 2.51, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 97.02%, running_loss: 2.10, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 96.71%, running_loss: 2.18, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 97.33%, running_loss: 1.95, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 97.22%, running_loss: 2.28, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 96.81%, running_loss: 2.37, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 96.71%, running_loss: 2.26, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 96.86%, running_loss: 2.22, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 96.50%, running_loss: 2.35, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 96.35%, running_loss: 2.06, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 96.81%, running_loss: 2.19, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 96.86%, running_loss: 1.90, current_lr: 0.000001\n",
      "accuracy on validation set: 73.15%\n",
      "epoch: 0, accuracy: 3.96%, running_loss: 79.21, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 6.07%, running_loss: 78.08, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 9.41%, running_loss: 76.53, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 16.36%, running_loss: 70.59, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 29.17%, running_loss: 58.38, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 46.81%, running_loss: 41.09, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 58.90%, running_loss: 30.19, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 70.58%, running_loss: 21.24, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 75.77%, running_loss: 17.63, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 80.92%, running_loss: 12.64, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 84.41%, running_loss: 11.28, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 87.71%, running_loss: 8.68, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 88.43%, running_loss: 7.52, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 90.07%, running_loss: 6.70, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 90.69%, running_loss: 6.13, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 93.06%, running_loss: 5.09, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 93.57%, running_loss: 4.59, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 95.32%, running_loss: 3.54, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 95.37%, running_loss: 3.44, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 95.11%, running_loss: 3.02, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 97.12%, running_loss: 2.26, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 96.24%, running_loss: 2.40, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 97.17%, running_loss: 2.22, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 96.24%, running_loss: 2.65, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 96.91%, running_loss: 2.17, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 97.48%, running_loss: 1.85, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 97.02%, running_loss: 2.05, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 97.12%, running_loss: 2.01, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 97.38%, running_loss: 1.88, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 96.71%, running_loss: 1.96, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 97.27%, running_loss: 1.86, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 97.02%, running_loss: 1.99, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 97.33%, running_loss: 1.85, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 97.69%, running_loss: 1.64, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 97.17%, running_loss: 1.89, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 97.58%, running_loss: 1.68, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 96.91%, running_loss: 2.27, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 97.38%, running_loss: 2.08, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 96.86%, running_loss: 1.96, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 97.84%, running_loss: 1.85, current_lr: 0.000001\n",
      "accuracy on validation set: 72.69%\n",
      "epoch: 0, accuracy: 4.42%, running_loss: 79.18, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 5.20%, running_loss: 78.72, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 7.61%, running_loss: 77.81, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 15.95%, running_loss: 71.97, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 28.76%, running_loss: 59.69, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 45.88%, running_loss: 41.80, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 59.72%, running_loss: 29.80, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 67.95%, running_loss: 23.04, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 71.09%, running_loss: 19.68, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 79.06%, running_loss: 16.00, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 80.04%, running_loss: 14.76, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 85.39%, running_loss: 10.05, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 87.60%, running_loss: 8.87, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 88.48%, running_loss: 8.23, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 89.76%, running_loss: 7.00, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 91.98%, running_loss: 5.47, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 92.54%, running_loss: 4.81, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 93.21%, running_loss: 4.85, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 95.06%, running_loss: 3.53, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 96.40%, running_loss: 2.62, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 95.68%, running_loss: 3.11, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 96.35%, running_loss: 2.84, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 96.19%, running_loss: 2.56, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 96.24%, running_loss: 2.48, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 96.55%, running_loss: 2.24, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 96.66%, running_loss: 2.31, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 97.33%, running_loss: 1.95, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 97.07%, running_loss: 2.34, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 96.91%, running_loss: 2.03, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 96.81%, running_loss: 2.30, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 96.76%, running_loss: 2.23, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 97.22%, running_loss: 2.07, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 97.07%, running_loss: 2.04, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 96.91%, running_loss: 2.11, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 97.43%, running_loss: 1.87, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 97.48%, running_loss: 1.92, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 96.97%, running_loss: 2.11, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 97.02%, running_loss: 2.09, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 97.17%, running_loss: 1.83, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 97.38%, running_loss: 1.78, current_lr: 0.000001\n",
      "accuracy on validation set: 73.61%\n",
      "epoch: 0, accuracy: 3.91%, running_loss: 79.19, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 5.30%, running_loss: 78.68, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 9.00%, running_loss: 76.67, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 14.87%, running_loss: 72.90, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 28.29%, running_loss: 60.89, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 43.11%, running_loss: 44.78, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 55.97%, running_loss: 32.53, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 69.86%, running_loss: 22.37, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 76.39%, running_loss: 16.36, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 78.29%, running_loss: 14.83, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 84.16%, running_loss: 11.54, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 85.60%, running_loss: 10.04, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 88.17%, running_loss: 8.19, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 90.59%, running_loss: 7.31, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 90.23%, running_loss: 6.47, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 91.62%, running_loss: 5.78, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 93.78%, running_loss: 4.19, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 94.70%, running_loss: 3.62, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 95.47%, running_loss: 3.17, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 96.09%, running_loss: 2.62, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 97.17%, running_loss: 2.07, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 97.33%, running_loss: 2.16, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 96.91%, running_loss: 2.00, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 96.45%, running_loss: 2.58, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 96.71%, running_loss: 2.23, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 96.76%, running_loss: 2.14, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 96.86%, running_loss: 2.06, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 97.27%, running_loss: 1.93, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 97.02%, running_loss: 2.02, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 97.17%, running_loss: 2.13, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 96.81%, running_loss: 1.98, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 97.48%, running_loss: 2.02, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 97.27%, running_loss: 2.01, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 97.02%, running_loss: 1.87, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 97.89%, running_loss: 1.61, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 97.12%, running_loss: 1.84, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 97.12%, running_loss: 1.79, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 97.22%, running_loss: 1.96, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 97.17%, running_loss: 1.99, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 97.27%, running_loss: 1.93, current_lr: 0.000001\n",
      "accuracy on validation set: 73.15%\n",
      "epoch: 0, accuracy: 3.40%, running_loss: 79.80, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 4.94%, running_loss: 78.94, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 5.61%, running_loss: 77.92, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 10.60%, running_loss: 75.23, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 17.90%, running_loss: 69.58, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 31.58%, running_loss: 57.04, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 44.14%, running_loss: 46.24, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 53.24%, running_loss: 34.72, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 63.22%, running_loss: 26.69, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 70.83%, running_loss: 20.48, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 75.77%, running_loss: 17.32, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 81.38%, running_loss: 13.39, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 79.58%, running_loss: 13.77, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 85.19%, running_loss: 10.84, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 85.49%, running_loss: 9.93, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 88.68%, running_loss: 7.92, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 90.84%, running_loss: 5.90, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 91.62%, running_loss: 5.52, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 92.64%, running_loss: 4.94, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 94.29%, running_loss: 4.25, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 94.91%, running_loss: 3.34, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 95.37%, running_loss: 3.13, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 95.52%, running_loss: 2.90, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 95.47%, running_loss: 3.09, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 95.16%, running_loss: 3.30, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 95.42%, running_loss: 2.88, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 96.04%, running_loss: 2.63, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 96.30%, running_loss: 2.78, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 95.52%, running_loss: 3.00, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 95.37%, running_loss: 3.28, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 94.91%, running_loss: 3.16, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 96.60%, running_loss: 2.74, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 95.63%, running_loss: 2.69, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 95.88%, running_loss: 2.73, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 96.19%, running_loss: 2.75, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 95.73%, running_loss: 2.94, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 96.55%, running_loss: 2.69, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 96.19%, running_loss: 2.79, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 96.60%, running_loss: 2.29, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 95.94%, running_loss: 2.62, current_lr: 0.000001\n",
      "accuracy on validation set: 72.69%\n",
      "epoch: 0, accuracy: 3.60%, running_loss: 79.08, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 6.94%, running_loss: 77.80, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 9.77%, running_loss: 75.81, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 17.28%, running_loss: 70.00, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 30.56%, running_loss: 56.98, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 46.24%, running_loss: 42.99, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 56.94%, running_loss: 32.54, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 63.43%, running_loss: 25.71, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 73.35%, running_loss: 19.62, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 77.01%, running_loss: 15.61, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 83.38%, running_loss: 12.50, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 83.54%, running_loss: 11.22, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 84.41%, running_loss: 10.37, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 86.99%, running_loss: 9.02, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 87.60%, running_loss: 8.34, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 90.38%, running_loss: 7.01, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 92.23%, running_loss: 5.14, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 92.08%, running_loss: 5.81, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 92.44%, running_loss: 4.54, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 94.86%, running_loss: 3.61, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 95.47%, running_loss: 3.20, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 95.37%, running_loss: 3.08, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 95.94%, running_loss: 2.88, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 96.19%, running_loss: 2.70, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 95.63%, running_loss: 3.02, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 96.24%, running_loss: 2.70, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 96.30%, running_loss: 2.63, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 96.97%, running_loss: 2.26, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 95.88%, running_loss: 2.87, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 96.19%, running_loss: 2.68, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 96.55%, running_loss: 2.67, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 96.35%, running_loss: 2.36, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 96.40%, running_loss: 2.73, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 95.27%, running_loss: 2.96, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 96.55%, running_loss: 2.47, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 96.66%, running_loss: 2.42, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 97.02%, running_loss: 2.27, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 96.40%, running_loss: 2.62, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 96.86%, running_loss: 2.19, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 96.60%, running_loss: 2.25, current_lr: 0.000001\n",
      "accuracy on validation set: 72.69%\n",
      "epoch: 0, accuracy: 4.01%, running_loss: 79.11, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 5.50%, running_loss: 78.47, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 8.64%, running_loss: 76.84, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 15.64%, running_loss: 71.54, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 31.28%, running_loss: 56.43, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 46.60%, running_loss: 42.69, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 58.69%, running_loss: 31.74, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 65.95%, running_loss: 24.94, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 73.71%, running_loss: 19.79, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 74.13%, running_loss: 18.59, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 79.99%, running_loss: 13.53, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 84.93%, running_loss: 11.03, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 86.78%, running_loss: 9.22, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 88.48%, running_loss: 7.57, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 91.15%, running_loss: 6.26, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 90.95%, running_loss: 6.49, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 92.13%, running_loss: 5.56, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 93.62%, running_loss: 4.11, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 92.85%, running_loss: 4.75, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 94.70%, running_loss: 3.56, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 95.58%, running_loss: 2.99, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 96.55%, running_loss: 2.44, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 95.42%, running_loss: 2.81, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 96.30%, running_loss: 2.46, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 96.09%, running_loss: 2.66, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 96.30%, running_loss: 2.80, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 95.99%, running_loss: 2.71, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 96.91%, running_loss: 2.33, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 96.14%, running_loss: 2.65, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 95.63%, running_loss: 2.82, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 96.24%, running_loss: 2.61, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 95.83%, running_loss: 2.68, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 95.52%, running_loss: 2.91, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 95.42%, running_loss: 2.94, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 96.91%, running_loss: 1.94, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 96.71%, running_loss: 2.23, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 96.81%, running_loss: 2.16, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 95.99%, running_loss: 2.57, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 96.76%, running_loss: 2.10, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 96.76%, running_loss: 2.11, current_lr: 0.000001\n",
      "accuracy on validation set: 73.15%\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "device = 'cuda:0'\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=False)\n",
    "batch_size = 81\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "fold_train_acc = []\n",
    "fold_val_acc = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data)):\n",
    "    # 模型初始化\n",
    "    linear_model = nn.Sequential(\n",
    "        # nn.Linear(100, 200),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(200, 27)\n",
    "        nn.Linear(100, 400),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(400, 600),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(600, 200),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(200, 27)\n",
    "    )\n",
    "    linear_model = from_model(linear_model, batch_size=81, input_shape=(1, 700, 100), \n",
    "                              add_spiking_output=True).to(device)\n",
    "    optimizer = torch.optim.Adam(linear_model.parameters(), lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    # 分割数据集\n",
    "    train_sub = Subset(train_data, train_ids)\n",
    "    val_sub = Subset(train_data, val_ids)\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_sub, batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader  = DataLoader(val_sub, batch_size, drop_last=True)\n",
    "\n",
    "    # 训练模型\n",
    "    linear_model.train()\n",
    "    epochs = 40\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0.\n",
    "        acc = 0\n",
    "        scheduler.step()\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            linear_model.reset_states()\n",
    "\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(input)\n",
    "            sum_output = output.sum(1)\n",
    "            loss = loss_fn(sum_output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                if sum_output[j].argmax() == target[j]:\n",
    "                    acc += 1\n",
    "\n",
    "        print(\"epoch: %d, accuracy: %.2f%%, running_loss: %.2f, current_lr: %.6f\" \n",
    "              % (e, acc/len(train_sub)*100, running_loss, scheduler.get_last_lr()[0]) )\n",
    "    fold_train_acc.append(np.around(acc/len(train_sub)*100, 2))\n",
    "\n",
    "    # 验证模型\n",
    "    acc_num = 0\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            linear_model.reset_states()\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(data)\n",
    "            sum_output = output.sum(1)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            if sum_output[j].argmax() == target[j]:\n",
    "                acc_num += 1\n",
    "    print(\"accuracy on validation set: %.2f%%\" % (acc_num/len(val_sub)*100))\n",
    "    fold_val_acc.append(np.around(acc_num/len(val_sub)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96.24, 97.07, 96.09, 96.86, 97.84, 97.38, 97.27, 95.94, 96.6, 96.76]\n",
      "[68.52, 71.3, 72.22, 73.15, 72.69, 73.61, 73.15, 72.69, 72.69, 73.15]\n",
      "96.805\n",
      "72.317\n"
     ]
    }
   ],
   "source": [
    "print(fold_train_acc)\n",
    "print(fold_val_acc)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_train_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_val_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/speed200-depth2.5.pth'\n",
    "torch.save(linear_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testing set: 95.28%\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(model_path)\n",
    "test_loader  = DataLoader(test_data, batch_size, drop_last=True)\n",
    "\n",
    "acc_num = 0\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.reset_states()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        sum_output = output.sum(1)\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        if sum_output[j].argmax() == target[j]:\n",
    "            acc_num += 1\n",
    "print(\"accuracy on testing set: %.2f%%\" % (acc_num/len(test_data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synsense-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
