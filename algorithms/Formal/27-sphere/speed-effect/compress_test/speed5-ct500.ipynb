{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import sinabs\n",
    "import sinabs.activation\n",
    "import sinabs.layers as sl\n",
    "from sinabs.from_torch import from_model\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import KFold\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.data_path = os.listdir(self.root_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_name = self.data_path[idx]\n",
    "        data_item_path = os.path.join(self.root_dir, data_name)\n",
    "        with open(data_item_path, 'rb') as f:\n",
    "            data = np.load(f)\n",
    "\n",
    "        # ############## 测试压缩后的性能 ##############\n",
    "        # data_zeros = np.zeros((100, 350))\n",
    "        # data_zeros += data[:, ::2] + data[:, 1::2]\n",
    "        # data = data_zeros\n",
    "        # #############################################\n",
    "\n",
    "        data = torch.from_numpy(data).float()\n",
    "        data = torch.transpose(data, 0, 1)\n",
    "\n",
    "        if data_name[-6] == '_':\n",
    "            label = torch.tensor(eval(data_name[-5]), dtype=torch.long)\n",
    "        else:\n",
    "            label = torch.tensor(eval(data_name[-6:-4]), dtype=torch.long)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "root_dir_1 = 'F:\\Files\\PhD/Braille\\Data/braille-27letters-sphere/effect-speed/speed-v5-depth2.5/compress-test/compresstime-500/train'\n",
    "root_dir_2 = 'F:\\Files\\PhD/Braille\\Data/braille-27letters-sphere/effect-speed/speed-v5-depth2.5/compress-test/compresstime-500/test'\n",
    "\n",
    "train_data = MyData(root_dir_1)\n",
    "test_data  = MyData(root_dir_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 100])\n",
      "2160 1080\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][0].shape)\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 3.61%, running_loss: 72.51, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 4.50%, running_loss: 72.27, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 6.50%, running_loss: 71.44, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 8.78%, running_loss: 69.77, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 11.11%, running_loss: 67.85, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 15.00%, running_loss: 65.20, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 17.89%, running_loss: 62.02, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 25.33%, running_loss: 56.99, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 37.22%, running_loss: 47.36, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 46.33%, running_loss: 42.62, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 53.44%, running_loss: 36.11, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 56.56%, running_loss: 32.37, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 63.50%, running_loss: 27.48, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 66.50%, running_loss: 26.45, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 68.72%, running_loss: 23.72, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 73.94%, running_loss: 19.11, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 75.89%, running_loss: 18.60, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 78.06%, running_loss: 17.63, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 79.00%, running_loss: 16.93, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 83.06%, running_loss: 12.07, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 82.83%, running_loss: 11.94, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 84.06%, running_loss: 10.72, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 86.33%, running_loss: 9.27, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 84.61%, running_loss: 11.32, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 85.00%, running_loss: 11.05, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 85.39%, running_loss: 10.20, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 84.61%, running_loss: 11.28, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 85.67%, running_loss: 9.98, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 85.67%, running_loss: 10.06, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 84.94%, running_loss: 10.13, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 86.72%, running_loss: 9.07, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 87.50%, running_loss: 9.06, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 88.11%, running_loss: 8.17, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 86.67%, running_loss: 9.30, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 85.83%, running_loss: 10.42, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 85.83%, running_loss: 9.65, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 86.33%, running_loss: 9.26, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 87.39%, running_loss: 8.08, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 87.89%, running_loss: 8.16, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 87.56%, running_loss: 8.08, current_lr: 0.000001\n",
      "accuracy on validation set: 79.44%\n",
      "epoch: 0, accuracy: 3.61%, running_loss: 72.51, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 5.61%, running_loss: 71.89, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 8.22%, running_loss: 70.10, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 10.17%, running_loss: 68.42, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 13.22%, running_loss: 66.49, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 15.11%, running_loss: 64.04, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 22.17%, running_loss: 57.61, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 31.11%, running_loss: 51.19, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 40.22%, running_loss: 43.49, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 45.83%, running_loss: 39.30, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 50.22%, running_loss: 36.50, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 55.56%, running_loss: 30.46, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 59.22%, running_loss: 29.33, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 62.39%, running_loss: 28.17, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 68.78%, running_loss: 21.08, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 70.89%, running_loss: 22.53, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 74.11%, running_loss: 19.40, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 76.44%, running_loss: 16.76, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 78.78%, running_loss: 16.32, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 81.61%, running_loss: 13.47, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 82.89%, running_loss: 10.93, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 83.50%, running_loss: 11.88, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 84.17%, running_loss: 10.91, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 82.72%, running_loss: 11.41, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 83.22%, running_loss: 11.13, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 83.67%, running_loss: 11.33, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 82.67%, running_loss: 12.50, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 84.28%, running_loss: 10.98, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 82.56%, running_loss: 11.95, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 84.06%, running_loss: 10.59, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 84.72%, running_loss: 10.14, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 84.50%, running_loss: 10.78, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 83.94%, running_loss: 11.04, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 85.11%, running_loss: 10.68, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 84.89%, running_loss: 10.75, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 86.28%, running_loss: 9.49, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 86.11%, running_loss: 10.28, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 84.44%, running_loss: 10.71, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 85.89%, running_loss: 9.59, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 85.67%, running_loss: 9.53, current_lr: 0.000001\n",
      "accuracy on validation set: 77.78%\n",
      "epoch: 0, accuracy: 3.72%, running_loss: 72.51, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.89%, running_loss: 72.46, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 6.28%, running_loss: 71.70, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 8.11%, running_loss: 70.17, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 11.22%, running_loss: 68.12, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 13.72%, running_loss: 66.06, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 16.22%, running_loss: 63.18, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 24.00%, running_loss: 58.03, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 34.61%, running_loss: 50.88, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 41.33%, running_loss: 45.96, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 47.22%, running_loss: 42.27, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 53.17%, running_loss: 36.23, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 56.22%, running_loss: 33.48, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 60.33%, running_loss: 30.04, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 64.22%, running_loss: 28.33, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 68.17%, running_loss: 25.04, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 70.83%, running_loss: 21.95, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 73.44%, running_loss: 20.65, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 75.94%, running_loss: 19.05, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 78.83%, running_loss: 17.06, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 79.39%, running_loss: 14.47, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 80.78%, running_loss: 12.76, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 80.39%, running_loss: 14.19, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 82.39%, running_loss: 13.06, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 81.78%, running_loss: 13.29, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 79.94%, running_loss: 13.70, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 80.33%, running_loss: 13.68, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 82.61%, running_loss: 13.05, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 82.50%, running_loss: 12.66, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 82.00%, running_loss: 12.08, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 83.56%, running_loss: 12.12, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 83.22%, running_loss: 11.37, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 83.83%, running_loss: 11.35, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 82.61%, running_loss: 11.29, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 84.22%, running_loss: 11.31, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 82.28%, running_loss: 12.86, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 84.56%, running_loss: 11.46, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 84.17%, running_loss: 12.14, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 84.06%, running_loss: 11.17, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 83.33%, running_loss: 11.75, current_lr: 0.000001\n",
      "accuracy on validation set: 77.50%\n",
      "epoch: 0, accuracy: 3.61%, running_loss: 72.51, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 4.94%, running_loss: 72.25, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 7.67%, running_loss: 71.14, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 9.83%, running_loss: 69.03, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 13.67%, running_loss: 66.80, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 17.00%, running_loss: 63.24, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 22.44%, running_loss: 58.24, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 31.44%, running_loss: 50.34, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 43.11%, running_loss: 43.91, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 49.50%, running_loss: 36.77, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 54.61%, running_loss: 32.49, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 60.22%, running_loss: 28.92, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 62.67%, running_loss: 27.27, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 67.94%, running_loss: 24.69, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 68.11%, running_loss: 24.01, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 70.67%, running_loss: 22.39, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 74.22%, running_loss: 19.79, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 73.17%, running_loss: 20.81, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 74.06%, running_loss: 20.87, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 80.67%, running_loss: 14.94, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 84.00%, running_loss: 11.09, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 82.50%, running_loss: 11.67, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 82.56%, running_loss: 12.25, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 84.22%, running_loss: 11.29, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 84.17%, running_loss: 10.89, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 83.61%, running_loss: 11.20, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 84.56%, running_loss: 10.90, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 84.39%, running_loss: 10.12, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 83.83%, running_loss: 11.04, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 85.06%, running_loss: 10.14, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 85.28%, running_loss: 10.05, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 85.39%, running_loss: 9.77, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 84.94%, running_loss: 10.69, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 84.67%, running_loss: 10.63, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 85.83%, running_loss: 10.13, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 86.06%, running_loss: 9.35, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 85.39%, running_loss: 9.64, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 86.11%, running_loss: 9.54, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 84.89%, running_loss: 10.25, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 86.22%, running_loss: 9.18, current_lr: 0.000001\n",
      "accuracy on validation set: 78.89%\n",
      "epoch: 0, accuracy: 3.67%, running_loss: 72.51, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 4.06%, running_loss: 72.44, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 6.56%, running_loss: 71.33, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 10.61%, running_loss: 68.78, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 13.56%, running_loss: 66.55, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 15.28%, running_loss: 64.27, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 20.17%, running_loss: 61.08, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 31.72%, running_loss: 50.23, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 43.72%, running_loss: 41.38, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 50.61%, running_loss: 36.89, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 54.06%, running_loss: 33.33, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 61.28%, running_loss: 28.17, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 63.61%, running_loss: 26.59, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 67.78%, running_loss: 23.21, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 71.44%, running_loss: 20.75, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 72.28%, running_loss: 20.17, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 74.61%, running_loss: 17.11, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 76.89%, running_loss: 16.29, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 81.44%, running_loss: 13.98, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 82.22%, running_loss: 11.72, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 85.00%, running_loss: 9.58, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 84.83%, running_loss: 9.48, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 85.94%, running_loss: 8.73, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 85.50%, running_loss: 9.60, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 84.56%, running_loss: 9.58, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 86.33%, running_loss: 8.91, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 85.67%, running_loss: 9.19, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 87.56%, running_loss: 8.82, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 85.50%, running_loss: 9.91, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 87.50%, running_loss: 8.20, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 85.56%, running_loss: 8.88, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 87.89%, running_loss: 8.04, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 86.61%, running_loss: 8.65, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 87.22%, running_loss: 8.98, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 86.72%, running_loss: 8.87, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 87.28%, running_loss: 8.30, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 88.83%, running_loss: 7.26, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 88.00%, running_loss: 7.23, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 86.89%, running_loss: 8.01, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 87.78%, running_loss: 7.58, current_lr: 0.000001\n",
      "accuracy on validation set: 80.56%\n",
      "epoch: 0, accuracy: 3.67%, running_loss: 72.51, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 4.56%, running_loss: 72.30, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 7.11%, running_loss: 70.55, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 9.44%, running_loss: 69.06, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 12.06%, running_loss: 67.05, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 14.61%, running_loss: 64.59, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 18.28%, running_loss: 62.20, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 23.78%, running_loss: 57.01, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 34.33%, running_loss: 48.20, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 45.06%, running_loss: 41.30, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 54.44%, running_loss: 33.63, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 59.78%, running_loss: 29.91, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 64.61%, running_loss: 27.25, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 67.61%, running_loss: 25.81, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 72.44%, running_loss: 21.89, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 72.28%, running_loss: 22.61, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 74.56%, running_loss: 20.24, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 79.67%, running_loss: 16.22, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 81.72%, running_loss: 14.54, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 84.06%, running_loss: 10.97, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 85.72%, running_loss: 8.74, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 86.00%, running_loss: 8.93, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 86.33%, running_loss: 9.37, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 86.39%, running_loss: 8.49, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 86.44%, running_loss: 8.98, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 87.33%, running_loss: 9.24, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 87.22%, running_loss: 9.16, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 86.72%, running_loss: 8.46, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 87.28%, running_loss: 8.07, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 87.56%, running_loss: 8.65, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 87.00%, running_loss: 8.88, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 87.17%, running_loss: 8.60, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 86.61%, running_loss: 9.17, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 87.39%, running_loss: 8.28, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 88.11%, running_loss: 7.36, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 89.06%, running_loss: 8.28, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 88.06%, running_loss: 8.26, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 88.11%, running_loss: 8.10, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 87.83%, running_loss: 8.79, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 87.28%, running_loss: 8.80, current_lr: 0.000001\n",
      "accuracy on validation set: 81.11%\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "device = 'cuda:0'\n",
    "k_folds = 6\n",
    "kfold = KFold(n_splits=k_folds, shuffle=False)\n",
    "batch_size = 81\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "fold_train_acc = []\n",
    "fold_val_acc = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data)):\n",
    "    # 模型初始化\n",
    "    linear_model = nn.Sequential(\n",
    "        # nn.Linear(100, 200),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(200, 27)\n",
    "        nn.Linear(100, 400),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(400, 600),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(600, 200),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(200, 27)\n",
    "    )\n",
    "    linear_model = from_model(linear_model, batch_size=81, input_shape=(1, 500, 100), \n",
    "                              add_spiking_output=True).to(device)\n",
    "    optimizer = torch.optim.Adam(linear_model.parameters(), lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    # 分割数据集\n",
    "    train_sub = Subset(train_data, train_ids)\n",
    "    val_sub = Subset(train_data, val_ids)\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_sub, batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader  = DataLoader(val_sub, batch_size, drop_last=True)\n",
    "\n",
    "    # 训练模型\n",
    "    linear_model.train()\n",
    "    epochs = 40\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0.\n",
    "        acc = 0\n",
    "        scheduler.step()\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            linear_model.reset_states()\n",
    "\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(input)\n",
    "            sum_output = output.sum(1)\n",
    "            loss = loss_fn(sum_output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                if sum_output[j].argmax() == target[j]:\n",
    "                    acc += 1\n",
    "\n",
    "        print(\"epoch: %d, accuracy: %.2f%%, running_loss: %.2f, current_lr: %.6f\" \n",
    "              % (e, acc/len(train_sub)*100, running_loss, scheduler.get_last_lr()[0]) )\n",
    "    fold_train_acc.append(np.around(acc/len(train_sub)*100, 2))\n",
    "\n",
    "    # 验证模型\n",
    "    acc_num = 0\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            linear_model.reset_states()\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(data)\n",
    "            sum_output = output.sum(1)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            if sum_output[j].argmax() == target[j]:\n",
    "                acc_num += 1\n",
    "    print(\"accuracy on validation set: %.2f%%\" % (acc_num/len(val_sub)*100))\n",
    "    fold_val_acc.append(np.around(acc_num/len(val_sub)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87.56, 85.67, 83.33, 86.22, 87.78, 87.28]\n",
      "[79.44, 77.78, 77.5, 78.89, 80.56, 81.11]\n",
      "86.30666666666666\n",
      "79.21333333333334\n"
     ]
    }
   ],
   "source": [
    "print(fold_train_acc)\n",
    "print(fold_val_acc)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_train_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_val_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/speed5-ct500.pth'\n",
    "torch.save(linear_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testing set: 83.61%\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(model_path)\n",
    "test_loader  = DataLoader(test_data, batch_size, drop_last=True)\n",
    "\n",
    "acc_num = 0\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.reset_states()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        sum_output = output.sum(1)\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        if sum_output[j].argmax() == target[j]:\n",
    "            acc_num += 1\n",
    "print(\"accuracy on testing set: %.2f%%\" % (acc_num/len(test_data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synsense-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
