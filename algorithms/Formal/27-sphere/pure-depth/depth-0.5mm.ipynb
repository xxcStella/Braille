{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import sinabs\n",
    "import sinabs.activation\n",
    "import sinabs.layers as sl\n",
    "from sinabs.from_torch import from_model\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import KFold\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.data_path = os.listdir(self.root_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_name = self.data_path[idx]\n",
    "        data_item_path = os.path.join(self.root_dir, data_name)\n",
    "        with open(data_item_path, 'rb') as f:\n",
    "            data = np.load(f)\n",
    "\n",
    "        data = torch.from_numpy(data).float()\n",
    "        data = torch.transpose(data, 0, 1)\n",
    "\n",
    "        if data_name[-6] == '_':\n",
    "            label = torch.tensor(eval(data_name[-5]), dtype=torch.long)\n",
    "        else:\n",
    "            label = torch.tensor(eval(data_name[-6:-4]), dtype=torch.long)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "root_dir_1 = 'F:\\Files\\PhD\\Braille\\Data/braille-27letters-sphere/depth/depth-0.5mm/train'\n",
    "root_dir_2 = 'F:\\Files\\PhD\\Braille\\Data/braille-27letters-sphere/depth/depth-0.5mm/test'\n",
    "\n",
    "train_data = MyData(root_dir_1)\n",
    "test_data  = MyData(root_dir_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([700, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Softwares\\Professional\\Anaconda3\\envs\\synsense-gpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.70%, running_loss: 148.30, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 7.71%, running_loss: 141.07, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 11.58%, running_loss: 135.31, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 18.44%, running_loss: 126.64, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 24.14%, running_loss: 116.61, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 28.34%, running_loss: 109.85, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 32.04%, running_loss: 104.34, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 32.65%, running_loss: 102.59, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 34.05%, running_loss: 101.10, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 36.41%, running_loss: 97.36, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 38.35%, running_loss: 95.84, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 40.36%, running_loss: 93.10, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 42.19%, running_loss: 90.91, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 45.02%, running_loss: 86.91, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 49.38%, running_loss: 84.44, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 50.73%, running_loss: 82.11, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 53.44%, running_loss: 78.50, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 54.05%, running_loss: 76.60, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 55.56%, running_loss: 76.01, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 56.02%, running_loss: 74.15, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 55.88%, running_loss: 73.65, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 56.35%, running_loss: 73.81, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 55.58%, running_loss: 73.73, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 55.47%, running_loss: 74.95, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 56.54%, running_loss: 72.45, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 56.02%, running_loss: 73.71, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 56.74%, running_loss: 72.62, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 56.90%, running_loss: 73.13, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 57.09%, running_loss: 72.42, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 56.68%, running_loss: 72.75, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 56.84%, running_loss: 72.41, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 57.26%, running_loss: 72.91, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 56.74%, running_loss: 72.90, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 56.60%, running_loss: 72.23, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 57.01%, running_loss: 71.30, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 57.20%, running_loss: 70.37, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 57.83%, running_loss: 71.23, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 57.59%, running_loss: 72.28, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 57.59%, running_loss: 71.65, current_lr: 0.000001\n",
      "accuracy on validation set: 57.78%\n",
      "epoch: 0, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.79%, running_loss: 148.26, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 8.89%, running_loss: 138.84, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 14.27%, running_loss: 131.98, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 19.67%, running_loss: 125.26, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 25.27%, running_loss: 115.56, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 28.37%, running_loss: 110.16, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 30.51%, running_loss: 107.16, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 33.17%, running_loss: 103.38, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 34.87%, running_loss: 101.84, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 36.08%, running_loss: 98.80, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 38.46%, running_loss: 96.48, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 41.23%, running_loss: 92.52, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 44.17%, running_loss: 88.87, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 47.49%, running_loss: 84.57, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 50.81%, running_loss: 81.83, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 52.24%, running_loss: 80.34, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 52.98%, running_loss: 78.57, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 53.61%, running_loss: 79.09, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 54.02%, running_loss: 76.83, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 54.81%, running_loss: 73.71, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 55.88%, running_loss: 73.82, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 55.94%, running_loss: 73.65, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 55.34%, running_loss: 75.13, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 55.58%, running_loss: 75.07, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 56.05%, running_loss: 73.28, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 55.86%, running_loss: 74.35, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 56.52%, running_loss: 72.27, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 56.57%, running_loss: 73.37, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 56.19%, running_loss: 74.44, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 56.60%, running_loss: 72.82, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 56.32%, running_loss: 73.04, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 56.60%, running_loss: 73.35, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 56.24%, running_loss: 73.17, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 57.26%, running_loss: 71.54, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 57.04%, running_loss: 73.23, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 56.30%, running_loss: 73.06, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 57.45%, running_loss: 71.15, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 57.48%, running_loss: 70.76, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 58.19%, running_loss: 70.30, current_lr: 0.000001\n",
      "accuracy on validation set: 57.78%\n",
      "epoch: 0, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.70%, running_loss: 148.30, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 7.96%, running_loss: 140.56, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 10.51%, running_loss: 135.76, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 18.13%, running_loss: 127.44, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 24.42%, running_loss: 117.58, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 26.17%, running_loss: 112.63, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 29.57%, running_loss: 108.33, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 31.52%, running_loss: 104.91, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 33.55%, running_loss: 103.02, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 34.27%, running_loss: 100.81, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 37.26%, running_loss: 97.54, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 39.18%, running_loss: 95.44, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 41.18%, running_loss: 93.61, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 45.71%, running_loss: 85.40, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 49.47%, running_loss: 83.01, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 50.70%, running_loss: 80.28, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 52.81%, running_loss: 79.06, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 54.13%, running_loss: 75.83, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 55.94%, running_loss: 71.49, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 55.67%, running_loss: 73.03, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 56.43%, running_loss: 72.57, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 56.35%, running_loss: 71.71, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 55.53%, running_loss: 73.35, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 56.43%, running_loss: 71.42, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 56.49%, running_loss: 72.02, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 56.54%, running_loss: 71.03, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 56.35%, running_loss: 71.14, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 57.61%, running_loss: 70.30, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 56.71%, running_loss: 71.27, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 57.26%, running_loss: 70.91, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 57.12%, running_loss: 71.02, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 57.64%, running_loss: 70.23, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 57.70%, running_loss: 70.86, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 57.34%, running_loss: 70.17, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 57.04%, running_loss: 71.87, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 56.98%, running_loss: 71.46, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 57.94%, running_loss: 69.65, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 57.59%, running_loss: 72.57, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 57.61%, running_loss: 70.55, current_lr: 0.000001\n",
      "accuracy on validation set: 58.52%\n",
      "epoch: 0, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 7.49%, running_loss: 141.23, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 10.18%, running_loss: 136.32, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 16.79%, running_loss: 129.50, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 23.13%, running_loss: 118.18, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 28.01%, running_loss: 110.78, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 31.39%, running_loss: 106.35, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 33.61%, running_loss: 103.01, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 35.20%, running_loss: 99.24, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 37.12%, running_loss: 97.82, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 39.42%, running_loss: 93.69, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 41.07%, running_loss: 91.82, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 44.72%, running_loss: 88.11, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 48.94%, running_loss: 81.63, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 51.00%, running_loss: 80.74, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 53.22%, running_loss: 81.34, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 54.35%, running_loss: 79.34, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 53.58%, running_loss: 77.42, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 55.06%, running_loss: 75.11, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 55.56%, running_loss: 74.04, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 55.01%, running_loss: 74.44, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 55.64%, running_loss: 73.65, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 55.39%, running_loss: 74.53, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 55.61%, running_loss: 74.85, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 55.09%, running_loss: 74.73, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 55.86%, running_loss: 74.18, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 55.94%, running_loss: 73.70, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 55.58%, running_loss: 73.26, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 56.16%, running_loss: 73.56, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 56.43%, running_loss: 73.00, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 55.17%, running_loss: 76.13, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 56.76%, running_loss: 72.26, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 55.97%, running_loss: 74.44, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 56.63%, running_loss: 72.94, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 56.38%, running_loss: 74.51, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 56.65%, running_loss: 72.34, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 56.93%, running_loss: 73.64, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 56.63%, running_loss: 73.77, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 57.45%, running_loss: 72.60, current_lr: 0.000001\n",
      "accuracy on validation set: 56.54%\n",
      "epoch: 0, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.76%, running_loss: 148.29, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 8.34%, running_loss: 140.60, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 10.32%, running_loss: 135.75, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 16.46%, running_loss: 129.17, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 21.15%, running_loss: 122.05, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 26.26%, running_loss: 113.71, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 29.27%, running_loss: 109.15, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 31.60%, running_loss: 105.18, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 32.87%, running_loss: 104.32, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 35.36%, running_loss: 100.25, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 36.43%, running_loss: 98.67, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 38.96%, running_loss: 95.53, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 42.85%, running_loss: 90.98, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 45.98%, running_loss: 87.15, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 49.03%, running_loss: 83.09, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 50.89%, running_loss: 81.82, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 52.78%, running_loss: 79.37, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 53.39%, running_loss: 79.97, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 55.31%, running_loss: 75.14, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 54.92%, running_loss: 76.52, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 55.80%, running_loss: 73.94, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 55.61%, running_loss: 76.03, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 56.08%, running_loss: 72.88, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 55.36%, running_loss: 74.51, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 56.05%, running_loss: 74.70, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 55.86%, running_loss: 74.06, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 56.41%, running_loss: 74.11, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 56.57%, running_loss: 72.81, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 58.05%, running_loss: 70.83, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 57.01%, running_loss: 72.88, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 55.86%, running_loss: 74.98, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 57.09%, running_loss: 73.36, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 56.46%, running_loss: 73.10, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 56.43%, running_loss: 73.47, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 56.79%, running_loss: 73.80, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 57.04%, running_loss: 72.87, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 56.84%, running_loss: 72.63, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 56.46%, running_loss: 72.89, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 57.81%, running_loss: 73.07, current_lr: 0.000001\n",
      "accuracy on validation set: 56.30%\n",
      "epoch: 0, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.76%, running_loss: 148.24, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 8.48%, running_loss: 139.62, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 11.36%, running_loss: 135.37, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 19.78%, running_loss: 124.27, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 24.39%, running_loss: 115.45, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 28.12%, running_loss: 110.67, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 31.06%, running_loss: 106.04, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 33.58%, running_loss: 102.54, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 35.09%, running_loss: 100.28, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 36.87%, running_loss: 98.21, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 37.75%, running_loss: 96.22, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 39.42%, running_loss: 93.22, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 40.80%, running_loss: 92.35, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 44.33%, running_loss: 89.75, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 47.11%, running_loss: 86.94, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 49.41%, running_loss: 83.29, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 51.22%, running_loss: 81.71, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 52.78%, running_loss: 80.11, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 54.18%, running_loss: 77.79, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 53.72%, running_loss: 78.16, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 53.96%, running_loss: 77.78, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 54.84%, running_loss: 75.56, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 54.40%, running_loss: 75.87, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 54.49%, running_loss: 76.54, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 54.49%, running_loss: 76.80, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 55.23%, running_loss: 75.55, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 55.45%, running_loss: 74.65, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 54.73%, running_loss: 76.76, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 56.02%, running_loss: 75.01, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 55.50%, running_loss: 76.13, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 55.58%, running_loss: 74.59, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 56.13%, running_loss: 73.92, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 55.45%, running_loss: 76.04, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 55.25%, running_loss: 75.88, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 56.41%, running_loss: 73.83, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 56.05%, running_loss: 74.51, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 55.61%, running_loss: 74.77, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 56.27%, running_loss: 75.19, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 56.13%, running_loss: 74.40, current_lr: 0.000001\n",
      "accuracy on validation set: 57.53%\n",
      "epoch: 0, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 7.85%, running_loss: 141.02, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 12.57%, running_loss: 133.75, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 19.97%, running_loss: 123.57, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 25.43%, running_loss: 115.16, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 28.78%, running_loss: 110.46, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 30.78%, running_loss: 106.65, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 33.50%, running_loss: 102.41, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 35.28%, running_loss: 100.39, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 36.93%, running_loss: 97.88, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 38.79%, running_loss: 95.89, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 41.18%, running_loss: 93.16, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 45.24%, running_loss: 87.58, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 49.16%, running_loss: 83.42, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 51.96%, running_loss: 80.00, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 51.93%, running_loss: 80.68, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 53.50%, running_loss: 79.27, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 55.06%, running_loss: 75.54, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 56.46%, running_loss: 73.52, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 57.50%, running_loss: 71.39, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 56.41%, running_loss: 73.41, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 57.26%, running_loss: 71.59, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 57.09%, running_loss: 71.64, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 57.56%, running_loss: 71.32, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 57.20%, running_loss: 71.55, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 57.67%, running_loss: 70.56, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 57.42%, running_loss: 71.26, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 57.91%, running_loss: 71.71, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 58.05%, running_loss: 70.83, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 57.91%, running_loss: 70.72, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 59.07%, running_loss: 69.80, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 58.44%, running_loss: 70.43, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 57.81%, running_loss: 71.00, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 58.49%, running_loss: 68.68, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 58.52%, running_loss: 68.73, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 58.74%, running_loss: 68.91, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 57.78%, running_loss: 70.09, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 58.16%, running_loss: 69.93, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 58.35%, running_loss: 70.20, current_lr: 0.000001\n",
      "accuracy on validation set: 59.51%\n",
      "epoch: 0, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.70%, running_loss: 148.30, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 7.54%, running_loss: 141.85, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 11.06%, running_loss: 135.53, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 15.91%, running_loss: 130.31, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 21.54%, running_loss: 121.68, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 26.26%, running_loss: 112.97, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 30.32%, running_loss: 107.70, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 32.32%, running_loss: 105.04, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 33.69%, running_loss: 103.03, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 34.60%, running_loss: 100.17, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 37.61%, running_loss: 97.35, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 41.07%, running_loss: 92.85, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 44.20%, running_loss: 88.79, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 46.80%, running_loss: 83.46, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 48.78%, running_loss: 84.46, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 52.07%, running_loss: 79.10, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 51.74%, running_loss: 79.90, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 53.50%, running_loss: 77.88, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 54.95%, running_loss: 75.19, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 54.92%, running_loss: 73.19, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 55.14%, running_loss: 73.00, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 55.80%, running_loss: 73.03, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 56.13%, running_loss: 72.55, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 55.14%, running_loss: 73.79, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 55.64%, running_loss: 74.15, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 56.05%, running_loss: 73.17, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 56.24%, running_loss: 73.18, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 55.83%, running_loss: 73.66, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 56.24%, running_loss: 72.05, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 57.09%, running_loss: 71.45, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 56.46%, running_loss: 72.05, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 56.63%, running_loss: 72.57, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 56.57%, running_loss: 72.35, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 56.90%, running_loss: 71.96, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 56.41%, running_loss: 72.57, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 57.72%, running_loss: 71.33, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 56.52%, running_loss: 72.50, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 56.93%, running_loss: 72.04, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 58.27%, running_loss: 71.19, current_lr: 0.000001\n",
      "accuracy on validation set: 54.81%\n",
      "epoch: 0, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 7.71%, running_loss: 140.92, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 10.81%, running_loss: 136.10, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 15.36%, running_loss: 130.74, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 23.70%, running_loss: 118.66, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 27.87%, running_loss: 112.01, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 30.29%, running_loss: 107.59, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 32.54%, running_loss: 104.13, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 34.29%, running_loss: 101.37, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 36.30%, running_loss: 99.35, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 38.44%, running_loss: 96.45, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 42.28%, running_loss: 91.69, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 45.35%, running_loss: 86.45, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 48.45%, running_loss: 82.83, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 50.64%, running_loss: 81.11, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 53.20%, running_loss: 79.66, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 53.17%, running_loss: 79.66, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 54.81%, running_loss: 76.26, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 54.71%, running_loss: 75.81, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 55.67%, running_loss: 74.66, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 55.97%, running_loss: 74.45, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 56.13%, running_loss: 73.71, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 56.10%, running_loss: 73.18, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 56.21%, running_loss: 74.09, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 56.68%, running_loss: 75.16, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 56.21%, running_loss: 72.66, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 56.65%, running_loss: 72.49, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 56.74%, running_loss: 73.42, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 56.60%, running_loss: 72.11, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 55.75%, running_loss: 72.87, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 56.63%, running_loss: 73.84, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 57.56%, running_loss: 71.23, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 56.24%, running_loss: 73.04, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 57.50%, running_loss: 70.73, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 57.06%, running_loss: 72.91, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 56.46%, running_loss: 71.04, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 56.93%, running_loss: 72.85, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 57.01%, running_loss: 72.51, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 56.90%, running_loss: 72.58, current_lr: 0.000001\n",
      "accuracy on validation set: 57.78%\n",
      "epoch: 0, accuracy: 3.70%, running_loss: 148.31, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 3.90%, running_loss: 148.17, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 8.83%, running_loss: 138.61, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 11.80%, running_loss: 134.53, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 19.53%, running_loss: 125.04, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 24.99%, running_loss: 115.52, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 28.86%, running_loss: 109.73, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 30.53%, running_loss: 106.87, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 32.89%, running_loss: 103.26, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 35.28%, running_loss: 99.50, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 36.41%, running_loss: 98.57, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 37.86%, running_loss: 96.05, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 40.16%, running_loss: 93.81, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 41.87%, running_loss: 91.58, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 45.82%, running_loss: 86.77, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 49.11%, running_loss: 83.48, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 51.28%, running_loss: 81.30, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 53.55%, running_loss: 78.61, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 53.83%, running_loss: 79.00, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 54.68%, running_loss: 76.78, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 55.97%, running_loss: 73.92, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 55.28%, running_loss: 74.78, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 55.56%, running_loss: 74.37, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 56.35%, running_loss: 73.32, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 56.35%, running_loss: 73.09, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 56.43%, running_loss: 73.10, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 56.16%, running_loss: 72.10, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 55.72%, running_loss: 74.09, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 56.84%, running_loss: 71.81, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 56.41%, running_loss: 73.20, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 57.34%, running_loss: 71.63, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 55.99%, running_loss: 72.54, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 56.10%, running_loss: 73.21, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 57.17%, running_loss: 72.76, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 57.26%, running_loss: 71.56, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 56.52%, running_loss: 72.75, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 56.84%, running_loss: 73.34, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 57.72%, running_loss: 70.20, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 57.50%, running_loss: 71.10, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 57.70%, running_loss: 72.11, current_lr: 0.000001\n",
      "accuracy on validation set: 55.80%\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "device = 'cuda:0'\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=False)\n",
    "batch_size = 81\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "fold_train_acc = []\n",
    "fold_val_acc = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data)):\n",
    "    # 模型初始化\n",
    "    linear_model = nn.Sequential(\n",
    "        # nn.Linear(100, 200),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(200, 27)\n",
    "        nn.Linear(100, 400),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(400, 600),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(600, 200),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(200, 27)\n",
    "    )\n",
    "    linear_model = from_model(linear_model, batch_size=81, input_shape=(1, 700, 100), \n",
    "                              add_spiking_output=True).to(device)\n",
    "    optimizer = torch.optim.Adam(linear_model.parameters(), lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    # 分割数据集\n",
    "    train_sub = Subset(train_data, train_ids)\n",
    "    val_sub = Subset(train_data, val_ids)\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_sub, batch_size, shuffle=True)\n",
    "    val_loader  = DataLoader(val_sub, batch_size)\n",
    "\n",
    "    # 训练模型\n",
    "    linear_model.train()\n",
    "    epochs = 40\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0.\n",
    "        acc = 0\n",
    "        scheduler.step()\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            linear_model.reset_states()\n",
    "\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(input)\n",
    "            sum_output = output.sum(1)\n",
    "            loss = loss_fn(sum_output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                if sum_output[j].argmax() == target[j]:\n",
    "                    acc += 1\n",
    "\n",
    "        print(\"epoch: %d, accuracy: %.2f%%, running_loss: %.2f, current_lr: %.6f\" \n",
    "              % (e, acc/len(train_sub)*100, running_loss, scheduler.get_last_lr()[0]) )\n",
    "    fold_train_acc.append(np.around(acc/len(train_sub)*100, 2))\n",
    "\n",
    "    # 验证模型\n",
    "    acc_num = 0\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            linear_model.reset_states()\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(data)\n",
    "            sum_output = output.sum(1)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            if sum_output[j].argmax() == target[j]:\n",
    "                acc_num += 1\n",
    "    print(\"accuracy on validation set: %.2f%%\" % (acc_num/len(val_sub)*100))\n",
    "    fold_val_acc.append(np.around(acc_num/len(val_sub)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57.59, 58.19, 57.61, 57.45, 57.81, 56.13, 58.35, 58.27, 56.9, 57.7]\n",
      "[57.78, 57.78, 58.52, 56.54, 56.3, 57.53, 59.51, 54.81, 57.78, 55.8]\n",
      "57.6\n",
      "57.235\n"
     ]
    }
   ],
   "source": [
    "print(fold_train_acc)\n",
    "print(fold_val_acc)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_train_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_val_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/depth-0.5mm.pth'\n",
    "torch.save(linear_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testing set: 58.53%\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(model_path)\n",
    "test_loader  = DataLoader(test_data, batch_size)\n",
    "\n",
    "acc_num = 0\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.reset_states()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        sum_output = output.sum(1)\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        if sum_output[j].argmax() == target[j]:\n",
    "            acc_num += 1\n",
    "print(\"accuracy on testing set: %.2f%%\" % (acc_num/len(test_data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synsense-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
