{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import sinabs\n",
    "import sinabs.activation\n",
    "import sinabs.layers as sl\n",
    "from sinabs.from_torch import from_model\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import KFold\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.data_path = os.listdir(self.root_dir)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_name = self.data_path[idx]\n",
    "        data_item_path = os.path.join(self.root_dir, data_name)\n",
    "        with open(data_item_path, 'rb') as f:\n",
    "            data = np.load(f)\n",
    "\n",
    "        data = torch.from_numpy(data).float()\n",
    "        data = torch.transpose(data, 0, 1)\n",
    "\n",
    "        label = torch.tensor(eval(data_name[-5]), dtype=torch.long)\n",
    "        \n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "root_dir_1 = 'F:\\Files\\PhD\\Braille\\Data/braille-27letters-sphere/depth/depth-3.0mm/train'\n",
    "root_dir_2 = 'F:\\Files\\PhD\\Braille\\Data/braille-27letters-sphere/depth/depth-3.0mm/test'\n",
    "\n",
    "train_data = MyData(root_dir_1)\n",
    "test_data  = MyData(root_dir_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([700, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Softwares\\Professional\\Anaconda3\\envs\\synsense-gpu\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, accuracy: 11.22%, running_loss: 157.19, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 13.80%, running_loss: 161.38, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 17.42%, running_loss: 175.91, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 23.05%, running_loss: 169.80, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 26.53%, running_loss: 165.91, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 31.06%, running_loss: 158.59, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 36.65%, running_loss: 146.96, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 41.76%, running_loss: 137.51, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 47.27%, running_loss: 123.96, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 51.96%, running_loss: 112.99, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 55.64%, running_loss: 106.32, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 60.14%, running_loss: 99.43, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 62.88%, running_loss: 89.38, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 66.64%, running_loss: 88.16, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 70.45%, running_loss: 71.70, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 72.65%, running_loss: 72.83, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 75.99%, running_loss: 56.23, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 78.98%, running_loss: 49.63, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 80.03%, running_loss: 47.61, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 83.13%, running_loss: 35.60, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 84.72%, running_loss: 34.71, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 85.16%, running_loss: 33.25, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 84.36%, running_loss: 33.00, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 84.83%, running_loss: 34.25, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 84.61%, running_loss: 33.37, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 84.42%, running_loss: 34.06, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 84.22%, running_loss: 33.21, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 84.53%, running_loss: 36.62, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 85.38%, running_loss: 32.28, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 85.68%, running_loss: 31.28, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 85.24%, running_loss: 32.60, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 85.02%, running_loss: 32.73, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 85.93%, running_loss: 30.43, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 86.72%, running_loss: 29.91, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 85.95%, running_loss: 31.81, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 86.36%, running_loss: 30.51, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 86.06%, running_loss: 28.54, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 86.53%, running_loss: 29.95, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 85.73%, running_loss: 32.93, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 87.63%, running_loss: 27.68, current_lr: 0.000001\n",
      "accuracy on validation set: 86.17%\n",
      "epoch: 0, accuracy: 11.44%, running_loss: 159.07, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 15.50%, running_loss: 152.76, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 20.52%, running_loss: 152.61, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 24.64%, running_loss: 152.93, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 29.41%, running_loss: 143.45, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 34.60%, running_loss: 142.46, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 40.80%, running_loss: 125.37, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 46.58%, running_loss: 117.42, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 50.01%, running_loss: 113.59, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 55.39%, running_loss: 100.03, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 55.53%, running_loss: 102.04, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 63.16%, running_loss: 78.77, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 65.10%, running_loss: 75.95, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 67.13%, running_loss: 78.14, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 71.88%, running_loss: 61.78, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 75.06%, running_loss: 59.02, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 75.01%, running_loss: 58.73, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 78.85%, running_loss: 49.71, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 78.93%, running_loss: 47.97, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 82.94%, running_loss: 36.11, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 84.31%, running_loss: 32.81, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 85.02%, running_loss: 30.03, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 84.99%, running_loss: 31.74, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 85.95%, running_loss: 30.77, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 85.05%, running_loss: 30.05, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 86.28%, running_loss: 28.05, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 86.45%, running_loss: 28.19, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 86.47%, running_loss: 28.20, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 86.23%, running_loss: 27.72, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 86.56%, running_loss: 29.30, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 86.28%, running_loss: 28.85, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 87.24%, running_loss: 27.10, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 87.30%, running_loss: 25.81, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 86.75%, running_loss: 28.73, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 87.93%, running_loss: 25.74, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 87.05%, running_loss: 27.45, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 87.35%, running_loss: 27.46, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 87.54%, running_loss: 25.68, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 88.15%, running_loss: 24.40, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 88.07%, running_loss: 26.96, current_lr: 0.000001\n",
      "accuracy on validation set: 87.65%\n",
      "epoch: 0, accuracy: 11.80%, running_loss: 155.06, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 13.72%, running_loss: 165.71, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 19.75%, running_loss: 160.52, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 22.74%, running_loss: 162.16, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 26.31%, running_loss: 158.18, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 31.33%, running_loss: 152.55, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 35.91%, running_loss: 138.27, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 40.11%, running_loss: 136.87, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 46.39%, running_loss: 118.93, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 50.21%, running_loss: 115.20, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 53.80%, running_loss: 106.27, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 59.01%, running_loss: 85.86, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 63.16%, running_loss: 83.10, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 66.67%, running_loss: 73.99, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 70.29%, running_loss: 67.18, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 72.59%, running_loss: 61.54, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 75.20%, running_loss: 54.95, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 78.74%, running_loss: 49.21, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 78.13%, running_loss: 53.49, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 83.13%, running_loss: 34.65, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 85.57%, running_loss: 29.85, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 85.13%, running_loss: 30.01, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 85.95%, running_loss: 28.61, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 85.32%, running_loss: 29.79, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 85.68%, running_loss: 27.96, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 85.84%, running_loss: 28.81, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 86.61%, running_loss: 27.56, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 86.04%, running_loss: 29.27, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 86.50%, running_loss: 28.18, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 85.84%, running_loss: 29.26, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 86.23%, running_loss: 27.72, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 87.16%, running_loss: 26.37, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 86.64%, running_loss: 28.71, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 86.86%, running_loss: 27.04, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 87.52%, running_loss: 26.46, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 88.01%, running_loss: 24.65, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 88.75%, running_loss: 24.38, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 87.49%, running_loss: 25.88, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 87.68%, running_loss: 23.67, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 88.67%, running_loss: 23.50, current_lr: 0.000001\n",
      "accuracy on validation set: 85.93%\n",
      "epoch: 0, accuracy: 11.41%, running_loss: 155.41, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 14.07%, running_loss: 159.46, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 19.07%, running_loss: 153.01, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 22.96%, running_loss: 155.46, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 26.64%, running_loss: 152.63, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 33.06%, running_loss: 146.49, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 37.04%, running_loss: 144.02, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 41.84%, running_loss: 136.61, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 46.67%, running_loss: 116.34, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 53.99%, running_loss: 109.32, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 57.78%, running_loss: 103.08, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 63.13%, running_loss: 81.33, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 68.48%, running_loss: 76.16, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 71.14%, running_loss: 66.94, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 76.16%, running_loss: 54.12, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 78.63%, running_loss: 49.51, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 79.26%, running_loss: 54.85, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 81.02%, running_loss: 46.03, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 84.55%, running_loss: 34.40, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 87.46%, running_loss: 27.51, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 87.87%, running_loss: 25.71, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 87.87%, running_loss: 26.82, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 88.34%, running_loss: 25.44, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 88.81%, running_loss: 23.30, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 88.31%, running_loss: 24.29, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 88.50%, running_loss: 23.70, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 88.72%, running_loss: 23.65, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 88.67%, running_loss: 22.94, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 88.42%, running_loss: 26.15, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 89.47%, running_loss: 22.28, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 90.10%, running_loss: 21.80, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 88.83%, running_loss: 24.53, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 89.93%, running_loss: 22.98, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 90.12%, running_loss: 20.68, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 89.82%, running_loss: 21.23, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 90.18%, running_loss: 22.52, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 89.82%, running_loss: 21.69, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 90.70%, running_loss: 19.38, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 91.50%, running_loss: 18.97, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 91.06%, running_loss: 19.33, current_lr: 0.000001\n",
      "accuracy on validation set: 92.35%\n",
      "epoch: 0, accuracy: 11.22%, running_loss: 155.93, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 14.60%, running_loss: 161.29, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 18.08%, running_loss: 153.38, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 21.12%, running_loss: 154.12, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 27.41%, running_loss: 147.44, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 31.77%, running_loss: 130.46, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 40.00%, running_loss: 122.72, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 43.98%, running_loss: 121.48, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 47.71%, running_loss: 112.58, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 50.97%, running_loss: 108.32, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 56.10%, running_loss: 92.67, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 60.99%, running_loss: 85.54, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 64.75%, running_loss: 77.27, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 68.83%, running_loss: 66.34, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 70.86%, running_loss: 60.11, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 75.75%, running_loss: 52.41, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 78.35%, running_loss: 47.80, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 78.52%, running_loss: 50.00, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 79.81%, running_loss: 44.76, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 83.98%, running_loss: 31.58, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 84.99%, running_loss: 30.11, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 85.46%, running_loss: 28.04, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 86.20%, running_loss: 28.93, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 86.20%, running_loss: 29.23, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 86.31%, running_loss: 26.17, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 87.16%, running_loss: 24.62, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 88.01%, running_loss: 23.00, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 86.72%, running_loss: 25.96, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 86.45%, running_loss: 26.50, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 86.31%, running_loss: 27.59, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 86.97%, running_loss: 26.32, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 87.65%, running_loss: 24.78, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 88.18%, running_loss: 23.69, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 87.82%, running_loss: 24.53, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 87.85%, running_loss: 24.13, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 88.20%, running_loss: 24.26, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 88.97%, running_loss: 21.89, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 89.52%, running_loss: 21.50, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 88.78%, running_loss: 21.71, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 89.68%, running_loss: 22.61, current_lr: 0.000001\n",
      "accuracy on validation set: 86.67%\n",
      "epoch: 0, accuracy: 11.99%, running_loss: 159.57, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 14.16%, running_loss: 163.72, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 19.15%, running_loss: 161.62, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 22.44%, running_loss: 154.83, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 29.41%, running_loss: 149.49, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 34.32%, running_loss: 139.63, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 39.04%, running_loss: 135.68, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 43.65%, running_loss: 122.76, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 48.18%, running_loss: 114.09, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 52.15%, running_loss: 98.71, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 57.59%, running_loss: 99.11, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 58.68%, running_loss: 91.14, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 64.80%, running_loss: 77.68, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 67.24%, running_loss: 71.07, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 71.85%, running_loss: 65.39, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 73.69%, running_loss: 61.12, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 78.77%, running_loss: 45.27, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 79.20%, running_loss: 44.65, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 82.28%, running_loss: 37.84, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 83.92%, running_loss: 32.92, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 85.76%, running_loss: 28.80, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 87.13%, running_loss: 27.10, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 86.83%, running_loss: 26.79, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 86.69%, running_loss: 25.73, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 86.80%, running_loss: 26.65, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 86.53%, running_loss: 28.65, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 87.16%, running_loss: 27.37, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 87.52%, running_loss: 25.80, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 88.23%, running_loss: 25.43, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 87.27%, running_loss: 26.08, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 88.31%, running_loss: 22.06, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 87.71%, running_loss: 27.04, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 87.46%, running_loss: 25.96, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 88.04%, running_loss: 24.81, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 88.94%, running_loss: 24.42, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 88.53%, running_loss: 24.08, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 88.31%, running_loss: 24.34, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 88.34%, running_loss: 23.15, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 90.53%, running_loss: 19.63, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 89.47%, running_loss: 22.23, current_lr: 0.000001\n",
      "accuracy on validation set: 89.88%\n",
      "epoch: 0, accuracy: 12.13%, running_loss: 153.60, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 14.18%, running_loss: 170.16, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 17.78%, running_loss: 162.50, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 20.19%, running_loss: 162.15, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 23.79%, running_loss: 165.07, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 30.45%, running_loss: 149.94, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 32.76%, running_loss: 145.58, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 40.00%, running_loss: 134.78, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 43.98%, running_loss: 131.69, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 50.89%, running_loss: 109.91, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 56.63%, running_loss: 99.16, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 62.36%, running_loss: 86.72, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 63.05%, running_loss: 87.16, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 67.35%, running_loss: 79.00, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 70.21%, running_loss: 72.59, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 74.27%, running_loss: 59.43, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 76.41%, running_loss: 61.87, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 77.09%, running_loss: 58.09, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 82.72%, running_loss: 40.56, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 85.02%, running_loss: 31.82, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 85.32%, running_loss: 29.77, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 85.65%, running_loss: 30.22, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 86.28%, running_loss: 30.48, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 86.45%, running_loss: 30.20, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 86.80%, running_loss: 29.07, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 86.83%, running_loss: 28.01, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 87.27%, running_loss: 28.62, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 87.22%, running_loss: 28.44, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 86.42%, running_loss: 28.73, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 87.33%, running_loss: 27.53, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 88.37%, running_loss: 25.77, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 88.18%, running_loss: 25.36, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 88.37%, running_loss: 25.76, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 88.53%, running_loss: 25.28, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 87.38%, running_loss: 26.03, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 88.75%, running_loss: 25.13, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 88.75%, running_loss: 26.68, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 89.96%, running_loss: 21.53, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 87.27%, running_loss: 28.38, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 89.22%, running_loss: 22.59, current_lr: 0.000001\n",
      "accuracy on validation set: 91.11%\n",
      "epoch: 0, accuracy: 13.33%, running_loss: 160.07, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 15.97%, running_loss: 155.70, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 18.98%, running_loss: 152.21, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 20.71%, running_loss: 155.19, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 25.08%, running_loss: 150.54, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 30.59%, running_loss: 139.28, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 35.61%, running_loss: 135.10, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 40.99%, running_loss: 123.13, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 46.58%, running_loss: 115.09, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 50.37%, running_loss: 106.59, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 53.94%, running_loss: 99.60, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 57.67%, running_loss: 97.50, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 62.50%, running_loss: 81.13, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 64.22%, running_loss: 80.70, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 68.20%, running_loss: 67.13, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 71.55%, running_loss: 63.13, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 73.88%, running_loss: 58.65, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 75.67%, running_loss: 57.92, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 79.18%, running_loss: 49.10, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 81.43%, running_loss: 38.32, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 83.81%, running_loss: 33.92, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 83.87%, running_loss: 31.59, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 84.55%, running_loss: 31.81, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 83.13%, running_loss: 35.75, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 84.69%, running_loss: 29.40, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 85.08%, running_loss: 30.69, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 86.15%, running_loss: 28.27, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 85.62%, running_loss: 27.71, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 85.79%, running_loss: 29.11, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 85.54%, running_loss: 28.49, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 85.51%, running_loss: 30.95, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 86.01%, running_loss: 26.20, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 86.09%, running_loss: 29.39, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 86.50%, running_loss: 29.24, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 85.10%, running_loss: 30.31, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 87.30%, running_loss: 26.14, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 86.89%, running_loss: 26.93, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 86.23%, running_loss: 28.97, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 87.22%, running_loss: 28.34, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 87.68%, running_loss: 25.44, current_lr: 0.000001\n",
      "accuracy on validation set: 86.91%\n",
      "epoch: 0, accuracy: 12.98%, running_loss: 159.69, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 13.47%, running_loss: 166.66, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 18.02%, running_loss: 170.97, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 23.07%, running_loss: 171.63, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 26.89%, running_loss: 169.32, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 29.25%, running_loss: 172.60, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 35.31%, running_loss: 152.34, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 42.41%, running_loss: 138.66, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 45.90%, running_loss: 128.60, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 50.45%, running_loss: 122.06, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 54.71%, running_loss: 105.83, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 58.22%, running_loss: 103.18, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 62.85%, running_loss: 93.54, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 67.27%, running_loss: 81.06, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 71.14%, running_loss: 72.03, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 71.08%, running_loss: 71.74, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 76.57%, running_loss: 57.79, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 75.80%, running_loss: 64.62, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 78.38%, running_loss: 54.45, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 83.13%, running_loss: 36.80, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 82.50%, running_loss: 39.36, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 83.21%, running_loss: 37.80, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 83.54%, running_loss: 35.73, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 83.65%, running_loss: 35.15, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 84.55%, running_loss: 33.59, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 84.17%, running_loss: 35.30, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 84.66%, running_loss: 35.12, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 84.31%, running_loss: 36.46, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 84.86%, running_loss: 33.23, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 85.93%, running_loss: 31.42, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 86.89%, running_loss: 31.55, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 85.16%, running_loss: 31.61, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 85.82%, running_loss: 31.61, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 85.93%, running_loss: 32.11, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 86.34%, running_loss: 29.79, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 85.46%, running_loss: 30.53, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 86.34%, running_loss: 29.03, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 86.36%, running_loss: 29.41, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 87.08%, running_loss: 27.98, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 87.74%, running_loss: 28.20, current_lr: 0.000001\n",
      "accuracy on validation set: 88.64%\n",
      "epoch: 0, accuracy: 12.29%, running_loss: 153.48, current_lr: 0.000100\n",
      "epoch: 1, accuracy: 13.80%, running_loss: 157.33, current_lr: 0.000100\n",
      "epoch: 2, accuracy: 16.95%, running_loss: 169.55, current_lr: 0.000100\n",
      "epoch: 3, accuracy: 21.84%, running_loss: 163.01, current_lr: 0.000100\n",
      "epoch: 4, accuracy: 24.88%, running_loss: 162.64, current_lr: 0.000100\n",
      "epoch: 5, accuracy: 30.29%, running_loss: 154.63, current_lr: 0.000100\n",
      "epoch: 6, accuracy: 33.58%, running_loss: 148.91, current_lr: 0.000100\n",
      "epoch: 7, accuracy: 40.99%, running_loss: 136.53, current_lr: 0.000100\n",
      "epoch: 8, accuracy: 45.24%, running_loss: 129.21, current_lr: 0.000100\n",
      "epoch: 9, accuracy: 51.39%, running_loss: 111.42, current_lr: 0.000100\n",
      "epoch: 10, accuracy: 54.73%, running_loss: 104.80, current_lr: 0.000100\n",
      "epoch: 11, accuracy: 57.39%, running_loss: 105.04, current_lr: 0.000100\n",
      "epoch: 12, accuracy: 62.94%, running_loss: 87.14, current_lr: 0.000100\n",
      "epoch: 13, accuracy: 66.26%, running_loss: 84.24, current_lr: 0.000100\n",
      "epoch: 14, accuracy: 68.83%, running_loss: 73.65, current_lr: 0.000100\n",
      "epoch: 15, accuracy: 71.88%, running_loss: 69.61, current_lr: 0.000100\n",
      "epoch: 16, accuracy: 72.46%, running_loss: 70.99, current_lr: 0.000100\n",
      "epoch: 17, accuracy: 77.15%, running_loss: 55.43, current_lr: 0.000100\n",
      "epoch: 18, accuracy: 77.37%, running_loss: 58.77, current_lr: 0.000100\n",
      "epoch: 19, accuracy: 83.16%, running_loss: 35.97, current_lr: 0.000010\n",
      "epoch: 20, accuracy: 84.28%, running_loss: 35.23, current_lr: 0.000010\n",
      "epoch: 21, accuracy: 84.72%, running_loss: 32.78, current_lr: 0.000010\n",
      "epoch: 22, accuracy: 86.01%, running_loss: 30.33, current_lr: 0.000010\n",
      "epoch: 23, accuracy: 84.86%, running_loss: 31.36, current_lr: 0.000010\n",
      "epoch: 24, accuracy: 84.86%, running_loss: 30.88, current_lr: 0.000010\n",
      "epoch: 25, accuracy: 85.46%, running_loss: 30.79, current_lr: 0.000010\n",
      "epoch: 26, accuracy: 85.40%, running_loss: 28.73, current_lr: 0.000010\n",
      "epoch: 27, accuracy: 85.02%, running_loss: 30.82, current_lr: 0.000010\n",
      "epoch: 28, accuracy: 86.23%, running_loss: 31.36, current_lr: 0.000010\n",
      "epoch: 29, accuracy: 85.73%, running_loss: 31.62, current_lr: 0.000010\n",
      "epoch: 30, accuracy: 86.04%, running_loss: 28.91, current_lr: 0.000010\n",
      "epoch: 31, accuracy: 87.08%, running_loss: 28.37, current_lr: 0.000010\n",
      "epoch: 32, accuracy: 86.83%, running_loss: 28.12, current_lr: 0.000010\n",
      "epoch: 33, accuracy: 85.82%, running_loss: 32.32, current_lr: 0.000010\n",
      "epoch: 34, accuracy: 88.70%, running_loss: 23.89, current_lr: 0.000010\n",
      "epoch: 35, accuracy: 87.19%, running_loss: 27.51, current_lr: 0.000010\n",
      "epoch: 36, accuracy: 87.46%, running_loss: 26.82, current_lr: 0.000010\n",
      "epoch: 37, accuracy: 88.04%, running_loss: 24.21, current_lr: 0.000010\n",
      "epoch: 38, accuracy: 87.68%, running_loss: 27.17, current_lr: 0.000010\n",
      "epoch: 39, accuracy: 88.29%, running_loss: 24.19, current_lr: 0.000001\n",
      "accuracy on validation set: 88.15%\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "device = 'cuda:0'\n",
    "k_folds = 10\n",
    "kfold = KFold(n_splits=k_folds, shuffle=False)\n",
    "batch_size = 81\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "fold_train_acc = []\n",
    "fold_val_acc = []\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data)):\n",
    "    # 模型初始化\n",
    "    linear_model = nn.Sequential(\n",
    "        # nn.Linear(100, 200),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(200, 27)\n",
    "        nn.Linear(100, 400),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(400, 600),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(600, 200),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(200, 27)\n",
    "    )\n",
    "    linear_model = from_model(linear_model, batch_size=81, input_shape=(1, 700, 100), \n",
    "                              add_spiking_output=True).to(device)\n",
    "    optimizer = torch.optim.Adam(linear_model.parameters(), lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    # 分割数据集\n",
    "    train_sub = Subset(train_data, train_ids)\n",
    "    val_sub = Subset(train_data, val_ids)\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_sub, batch_size, shuffle=True)\n",
    "    val_loader  = DataLoader(val_sub, batch_size)\n",
    "\n",
    "    # 训练模型\n",
    "    linear_model.train()\n",
    "    epochs = 40\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0.\n",
    "        acc = 0\n",
    "        scheduler.step()\n",
    "        for i, (input, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            linear_model.reset_states()\n",
    "\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(input)\n",
    "            sum_output = output.sum(1)\n",
    "            loss = loss_fn(sum_output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                if sum_output[j].argmax() == target[j]:\n",
    "                    acc += 1\n",
    "\n",
    "        print(\"epoch: %d, accuracy: %.2f%%, running_loss: %.2f, current_lr: %.6f\" \n",
    "              % (e, acc/len(train_sub)*100, running_loss, scheduler.get_last_lr()[0]) )\n",
    "    fold_train_acc.append(np.around(acc/len(train_sub)*100, 2))\n",
    "\n",
    "    # 验证模型\n",
    "    acc_num = 0\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            linear_model.reset_states()\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = linear_model(data)\n",
    "            sum_output = output.sum(1)\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            if sum_output[j].argmax() == target[j]:\n",
    "                acc_num += 1\n",
    "    print(\"accuracy on validation set: %.2f%%\" % (acc_num/len(val_sub)*100))\n",
    "    fold_val_acc.append(np.around(acc_num/len(val_sub)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87.63, 88.07, 88.67, 91.06, 89.68, 89.47, 89.22, 87.68, 87.74, 88.29]\n",
      "[86.17, 87.65, 85.93, 92.35, 86.67, 89.88, 91.11, 86.91, 88.64, 88.15]\n",
      "88.751\n",
      "88.346\n"
     ]
    }
   ],
   "source": [
    "print(fold_train_acc)\n",
    "print(fold_val_acc)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_train_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)\n",
    "\n",
    "sum = 0\n",
    "cnt = 0\n",
    "for i in fold_val_acc:\n",
    "    sum += i\n",
    "    cnt += 1\n",
    "print(sum/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/depth-3.0mm.pth'\n",
    "torch.save(linear_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testing set: 67.47%\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(model_path)\n",
    "test_loader  = DataLoader(test_data, batch_size)\n",
    "\n",
    "acc_num = 0\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.reset_states()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        sum_output = output.sum(1)\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        if sum_output[j].argmax() == target[j]:\n",
    "            acc_num += 1\n",
    "print(\"accuracy on testing set: %.2f%%\" % (acc_num/len(test_data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synsense-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
